{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"mount_file_id":"11be7dNQPtd6Mxb42JC7t2mDpHO-v7Guk","authorship_tag":"ABX9TyOblt2Sn12uVAK569T4t+bv"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU","gpuClass":"standard","widgets":{"application/vnd.jupyter.widget-state+json":{"2354776689524649af452cddee4d2e7c":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_7153528d813a4364a217b69817a437a1","IPY_MODEL_e234edcb20114c7b9e744eeed3b5cdb6","IPY_MODEL_765a3f1c6ab04fcfbcd8b311e967e95f"],"layout":"IPY_MODEL_adb8e06445464861ba8fd0a0522746e5"}},"7153528d813a4364a217b69817a437a1":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_b88d1f9880ca4f45bd3c844504ea067d","placeholder":"​","style":"IPY_MODEL_68ed0e3bbbd74c7aa671524bdb8c3887","value":"Downloading: 100%"}},"e234edcb20114c7b9e744eeed3b5cdb6":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_0fc4557429fb4f61820063293c6fb457","max":995526,"min":0,"orientation":"horizontal","style":"IPY_MODEL_8eb3cef9277048c5be8c6964111227f5","value":995526}},"765a3f1c6ab04fcfbcd8b311e967e95f":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_a43913d7090f497ea101dda06033fec3","placeholder":"​","style":"IPY_MODEL_d9ac8a134509439f95bcf8e976a99d75","value":" 996k/996k [00:00&lt;00:00, 1.75MB/s]"}},"adb8e06445464861ba8fd0a0522746e5":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b88d1f9880ca4f45bd3c844504ea067d":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"68ed0e3bbbd74c7aa671524bdb8c3887":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"0fc4557429fb4f61820063293c6fb457":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"8eb3cef9277048c5be8c6964111227f5":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"a43913d7090f497ea101dda06033fec3":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"d9ac8a134509439f95bcf8e976a99d75":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"ad7431ef9e5b4590a513493ee0d394a3":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_a2357f566d8b48f4afd522b433685400","IPY_MODEL_db30274f54d645bebc7f8ac70fa94e4b","IPY_MODEL_7325ced1f3a443a2b97f0c0080a335bf"],"layout":"IPY_MODEL_0df013c1496d4260a560a087624ca56f"}},"a2357f566d8b48f4afd522b433685400":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_94785e9dcf1e469e93cc78dd1da4e8b2","placeholder":"​","style":"IPY_MODEL_7e978144eb4e4a14b7a5e0ecb905dcb1","value":"Downloading: 100%"}},"db30274f54d645bebc7f8ac70fa94e4b":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_afe31579b16b4ca981dc8b452a1becc5","max":29,"min":0,"orientation":"horizontal","style":"IPY_MODEL_c62718e5e495420fb66fb94c5b97cee8","value":29}},"7325ced1f3a443a2b97f0c0080a335bf":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_082c2014f95049529e7a0126313d37c0","placeholder":"​","style":"IPY_MODEL_9e9641cb2b434d76ad992afaae5156f3","value":" 29.0/29.0 [00:00&lt;00:00, 1.25kB/s]"}},"0df013c1496d4260a560a087624ca56f":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"94785e9dcf1e469e93cc78dd1da4e8b2":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"7e978144eb4e4a14b7a5e0ecb905dcb1":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"afe31579b16b4ca981dc8b452a1becc5":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"c62718e5e495420fb66fb94c5b97cee8":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"082c2014f95049529e7a0126313d37c0":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"9e9641cb2b434d76ad992afaae5156f3":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"aee256b70ef44fe8af0459c64b67c05f":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_6ab77e1f110248c1947b359babaa5e7a","IPY_MODEL_649e68cad67a464f9f2b5998ef9fc6e1","IPY_MODEL_96275751c25a4da4ba5a267a31350531"],"layout":"IPY_MODEL_7372f77446e44bf09e22d90cf98387b2"}},"6ab77e1f110248c1947b359babaa5e7a":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_a1f72655ee1547ac9a2fc097d1691d99","placeholder":"​","style":"IPY_MODEL_e4e6837ff87244688ca8f036846229a1","value":"Downloading: 100%"}},"649e68cad67a464f9f2b5998ef9fc6e1":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_8084e7110a6c4ad586c0dde24192a7f0","max":625,"min":0,"orientation":"horizontal","style":"IPY_MODEL_74e28e1eecd34291bc96dc6ec7e03f48","value":625}},"96275751c25a4da4ba5a267a31350531":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_541c56e8530d4185a798e7cd73d5fe98","placeholder":"​","style":"IPY_MODEL_4a257cffacdc4559bbbff3e8dad0b3b9","value":" 625/625 [00:00&lt;00:00, 29.8kB/s]"}},"7372f77446e44bf09e22d90cf98387b2":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"a1f72655ee1547ac9a2fc097d1691d99":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"e4e6837ff87244688ca8f036846229a1":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"8084e7110a6c4ad586c0dde24192a7f0":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"74e28e1eecd34291bc96dc6ec7e03f48":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"541c56e8530d4185a798e7cd73d5fe98":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"4a257cffacdc4559bbbff3e8dad0b3b9":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"66850ceb71654cbf817d36655b7bfc89":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_6fe826ed553e459696b079a73c8cce67","IPY_MODEL_3c582e3a587d42b7a85830423e07ba4a","IPY_MODEL_e25012ded8474f219dd4b5665df3e40c"],"layout":"IPY_MODEL_337eed94ecd44bc1b14ed24f96d02cb5"}},"6fe826ed553e459696b079a73c8cce67":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_3249d864625346f4898e981f7bea211e","placeholder":"​","style":"IPY_MODEL_94b42ae3ab4a4160a2ab236d338610ca","value":"Downloading: 100%"}},"3c582e3a587d42b7a85830423e07ba4a":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_9f6cc3b9ec2a4bdbaced72b523d7b77b","max":714314041,"min":0,"orientation":"horizontal","style":"IPY_MODEL_2683b7a846324930be3b71ead3ec4b72","value":714314041}},"e25012ded8474f219dd4b5665df3e40c":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_1c4bdfef1ef54454afc4f3aeae95de1e","placeholder":"​","style":"IPY_MODEL_af093360ead94567a0935a8d5816d6f0","value":" 714M/714M [00:09&lt;00:00, 71.1MB/s]"}},"337eed94ecd44bc1b14ed24f96d02cb5":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"3249d864625346f4898e981f7bea211e":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"94b42ae3ab4a4160a2ab236d338610ca":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"9f6cc3b9ec2a4bdbaced72b523d7b77b":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"2683b7a846324930be3b71ead3ec4b72":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"1c4bdfef1ef54454afc4f3aeae95de1e":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"af093360ead94567a0935a8d5816d6f0":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"59d548d312cc434a91b4edc804f92818":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_8144706f38d543aca4caa246ea2cb3dd","IPY_MODEL_649a5c1b98764380a75af0fd8c465d5f","IPY_MODEL_bfd35328b164419f9a7e106e11ee0923"],"layout":"IPY_MODEL_5be6aa90465240dfb6707e3d28c514db"}},"8144706f38d543aca4caa246ea2cb3dd":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_a61914cc54124ebaa4c532271f421944","placeholder":"​","style":"IPY_MODEL_f7a842211be9411ebfc8ab6681362b1f","value":"  0%"}},"649a5c1b98764380a75af0fd8c465d5f":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"danger","description":"","description_tooltip":null,"layout":"IPY_MODEL_4eb6ca548bdb4dcb89540c8c1b8342aa","max":2,"min":0,"orientation":"horizontal","style":"IPY_MODEL_983816f06fe7419ca083822805baad69","value":0}},"bfd35328b164419f9a7e106e11ee0923":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_b32dbdf975104f7aa60518a286a3dfbc","placeholder":"​","style":"IPY_MODEL_fd3149320c39457ea43c049373b561f0","value":" 0/2 [00:00&lt;?, ?it/s]"}},"5be6aa90465240dfb6707e3d28c514db":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"a61914cc54124ebaa4c532271f421944":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"f7a842211be9411ebfc8ab6681362b1f":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"4eb6ca548bdb4dcb89540c8c1b8342aa":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"983816f06fe7419ca083822805baad69":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"b32dbdf975104f7aa60518a286a3dfbc":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"fd3149320c39457ea43c049373b561f0":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}}},"cells":[{"cell_type":"markdown","source":["# Colab 환경 설정"],"metadata":{"id":"OHEPsX_sTz_8"}},{"cell_type":"code","source":["!pip install -q -U \"tensorflow-text==2.8.*\""],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"_-GxjsoDTwQc","executionInfo":{"status":"ok","timestamp":1673953967601,"user_tz":-540,"elapsed":50678,"user":{"displayName":"송지빈","userId":"11346694006770834807"}},"outputId":"ab5a004f-c7c9-4d47-e941-833f485bb57a"},"execution_count":9,"outputs":[{"output_type":"stream","name":"stdout","text":["\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.9/4.9 MB\u001b[0m \u001b[31m37.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m498.0/498.0 MB\u001b[0m \u001b[31m3.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.4/1.4 MB\u001b[0m \u001b[31m54.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.8/5.8 MB\u001b[0m \u001b[31m96.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m462.3/462.3 KB\u001b[0m \u001b[31m38.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h"]}]},{"cell_type":"code","source":["!pip install -q tf-models-official==2.7.0"],"metadata":{"id":"azBkwT-rbgSa"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["!pip install transformers\n","!pip install pad_sequences"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Z7lDXhVidQ5l","executionInfo":{"status":"ok","timestamp":1673953890302,"user_tz":-540,"elapsed":13064,"user":{"displayName":"송지빈","userId":"11346694006770834807"}},"outputId":"5606c43c-042f-4fb6-a12e-53ef4290a749"},"execution_count":7,"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Requirement already satisfied: transformers in /usr/local/lib/python3.8/dist-packages (4.25.1)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.8/dist-packages (from transformers) (2022.6.2)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.8/dist-packages (from transformers) (3.9.0)\n","Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.8/dist-packages (from transformers) (1.21.6)\n","Requirement already satisfied: huggingface-hub<1.0,>=0.10.0 in /usr/local/lib/python3.8/dist-packages (from transformers) (0.11.1)\n","Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.8/dist-packages (from transformers) (4.64.1)\n","Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.8/dist-packages (from transformers) (6.0)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.8/dist-packages (from transformers) (21.3)\n","Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /usr/local/lib/python3.8/dist-packages (from transformers) (0.13.2)\n","Requirement already satisfied: requests in /usr/local/lib/python3.8/dist-packages (from transformers) (2.25.1)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.8/dist-packages (from huggingface-hub<1.0,>=0.10.0->transformers) (4.4.0)\n","Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.8/dist-packages (from packaging>=20.0->transformers) (3.0.9)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests->transformers) (2.10)\n","Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests->transformers) (1.24.3)\n","Requirement already satisfied: chardet<5,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests->transformers) (4.0.0)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests->transformers) (2022.12.7)\n","Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Requirement already satisfied: pad_sequences in /usr/local/lib/python3.8/dist-packages (0.6.1)\n"]}]},{"cell_type":"code","source":["import tensorflow as tf\n","import torch\n","\n","from transformers import BertTokenizer\n","from transformers import BertForSequenceClassification, AdamW, BertConfig\n","from transformers import get_linear_schedule_with_warmup\n","from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n","from keras_preprocessing.sequence import pad_sequences\n","from sklearn.model_selection import train_test_split\n","\n","import pandas as pd\n","import numpy as np\n","import random\n","import time\n","import datetime"],"metadata":{"id":"5MbYmZYWTsb6","executionInfo":{"status":"ok","timestamp":1673954015373,"user_tz":-540,"elapsed":950,"user":{"displayName":"송지빈","userId":"11346694006770834807"}}},"execution_count":11,"outputs":[]},{"cell_type":"code","source":["n_devices = torch.cuda.device_count()\n","print(n_devices)\n","\n","for i in range(n_devices):\n","    print(torch.cuda.get_device_name(i))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"jkLNJ_40dC8b","executionInfo":{"status":"ok","timestamp":1673954017997,"user_tz":-540,"elapsed":21,"user":{"displayName":"송지빈","userId":"11346694006770834807"}},"outputId":"bf197f36-dfbd-4643-c5ae-3a14e74b4d00"},"execution_count":12,"outputs":[{"output_type":"stream","name":"stdout","text":["1\n","Tesla T4\n"]}]},{"cell_type":"markdown","source":["# 데이터셋 불러오기"],"metadata":{"id":"7Sb8WyOjT1mz"}},{"cell_type":"markdown","source":["## 학습 데이터 불러오기"],"metadata":{"id":"evis2aBvd6g9"}},{"cell_type":"code","source":["df = pd.read_csv('/content/drive/MyDrive/동아리_스터디_대외활동/Solux/2학기/Solux_Honey_News/crawling/result_crawling/preprocessed_data.csv')\n","df"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":424},"id":"lXF2e8rbT3DJ","executionInfo":{"status":"ok","timestamp":1673954023696,"user_tz":-540,"elapsed":2304,"user":{"displayName":"송지빈","userId":"11346694006770834807"}},"outputId":"4a8513d3-8d4c-4840-f1b7-768c1b8b492c"},"execution_count":13,"outputs":[{"output_type":"execute_result","data":{"text/plain":["                                      title  news  \\\n","0         윤 대통령 “북 무인기 한 대 왔으면 우린 2~3대 보내라”  중앙일보   \n","1               노웅래 체포안 부결...與 \"이재명 방탄 예고편\"  중앙일보   \n","2        이재명 때린 17년전 이재명? '지자체 부정부패' 논문 재조명  중앙일보   \n","3    [단독] TBS 직원 10명중 6명 \"김어준 방송, 중립적이지 않다\"  중앙일보   \n","4        미사일 안쏘고 韓 흔든 北…대박난 '회색지대 도발' 더 세진다  중앙일보   \n","..                                      ...   ...   \n","395    43%가 ‘사표’…“소선거구제는 썩은 그릇에 국물 조금 붓는 것”   한겨레   \n","396         윤 대통령 지지율 41.2%…2주 연속 상승 [리얼미터]   한겨레   \n","397   민주, ‘이재명 수사’ 검사 16명 공개…국힘 “헌법 질서에 도전”   한겨레   \n","398         노란봉투법·양곡관리법·차별금지법…여야 이견 속 해 넘길판   한겨레   \n","399       ‘국민통합’ 꺼내든 정치인 사면…이번에도 국민 공감대는 없다   한겨레   \n","\n","                                           new_article  \n","0    윤석열 대통령 28일 북한 도발 에도 확실하게 응징 보복 라 그것 가장 강력한 수단...  \n","1    저번 주셨는데 뭘 주냐 저번 그거 잘 쓰고 있는데 라고 말 하는 노웅래 민주당 의원...  \n","2    이재명 민주당 대표 성남 FC 후 원금 의혹 관련 해 검찰 수사 받는 가운데 17년...  \n","3    정치 적 편향 논란 끊이지 않던 TBS 교통 방송 라디오 프로그램 김어준 뉴스 공장...  \n","4    북한 대남 도발 날로 교묘해지고 핵 ㆍ 미사일 같은 고 강도 도발 에다 지난 26일...  \n","..                                                 ...  \n","395  2020년 치러진 21 대 총선 참여 한 유권자 2874만 1408 표 가운데 10...  \n","396  윤석열 대통령 국정 지지율 2 주 연속 상승 해 41 대를 기록 했다 리얼미터 미디...  \n","397  민주당 이재명 대표 관련 한 수사 진행 중인 검사 사진 이름 담긴 자료 만들어 전국...  \n","398  여야 지난 24일 638조 7천억원 규모 내년 도 예산안 부수 법안 지각 처리 했지...  \n","399  윤석열 대통령 연말 특별사면 권 행사 앞두고 헌법 보장 된 대통령 사면권 에는 국민...  \n","\n","[400 rows x 3 columns]"],"text/html":["\n","  <div id=\"df-5c8a71fb-1746-44cc-91ac-69bef2b5e734\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>title</th>\n","      <th>news</th>\n","      <th>new_article</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>윤 대통령 “북 무인기 한 대 왔으면 우린 2~3대 보내라”</td>\n","      <td>중앙일보</td>\n","      <td>윤석열 대통령 28일 북한 도발 에도 확실하게 응징 보복 라 그것 가장 강력한 수단...</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>노웅래 체포안 부결...與 \"이재명 방탄 예고편\"</td>\n","      <td>중앙일보</td>\n","      <td>저번 주셨는데 뭘 주냐 저번 그거 잘 쓰고 있는데 라고 말 하는 노웅래 민주당 의원...</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>이재명 때린 17년전 이재명? '지자체 부정부패' 논문 재조명</td>\n","      <td>중앙일보</td>\n","      <td>이재명 민주당 대표 성남 FC 후 원금 의혹 관련 해 검찰 수사 받는 가운데 17년...</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>[단독] TBS 직원 10명중 6명 \"김어준 방송, 중립적이지 않다\"</td>\n","      <td>중앙일보</td>\n","      <td>정치 적 편향 논란 끊이지 않던 TBS 교통 방송 라디오 프로그램 김어준 뉴스 공장...</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>미사일 안쏘고 韓 흔든 北…대박난 '회색지대 도발' 더 세진다</td>\n","      <td>중앙일보</td>\n","      <td>북한 대남 도발 날로 교묘해지고 핵 ㆍ 미사일 같은 고 강도 도발 에다 지난 26일...</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>395</th>\n","      <td>43%가 ‘사표’…“소선거구제는 썩은 그릇에 국물 조금 붓는 것”</td>\n","      <td>한겨레</td>\n","      <td>2020년 치러진 21 대 총선 참여 한 유권자 2874만 1408 표 가운데 10...</td>\n","    </tr>\n","    <tr>\n","      <th>396</th>\n","      <td>윤 대통령 지지율 41.2%…2주 연속 상승 [리얼미터]</td>\n","      <td>한겨레</td>\n","      <td>윤석열 대통령 국정 지지율 2 주 연속 상승 해 41 대를 기록 했다 리얼미터 미디...</td>\n","    </tr>\n","    <tr>\n","      <th>397</th>\n","      <td>민주, ‘이재명 수사’ 검사 16명 공개…국힘 “헌법 질서에 도전”</td>\n","      <td>한겨레</td>\n","      <td>민주당 이재명 대표 관련 한 수사 진행 중인 검사 사진 이름 담긴 자료 만들어 전국...</td>\n","    </tr>\n","    <tr>\n","      <th>398</th>\n","      <td>노란봉투법·양곡관리법·차별금지법…여야 이견 속 해 넘길판</td>\n","      <td>한겨레</td>\n","      <td>여야 지난 24일 638조 7천억원 규모 내년 도 예산안 부수 법안 지각 처리 했지...</td>\n","    </tr>\n","    <tr>\n","      <th>399</th>\n","      <td>‘국민통합’ 꺼내든 정치인 사면…이번에도 국민 공감대는 없다</td>\n","      <td>한겨레</td>\n","      <td>윤석열 대통령 연말 특별사면 권 행사 앞두고 헌법 보장 된 대통령 사면권 에는 국민...</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>400 rows × 3 columns</p>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-5c8a71fb-1746-44cc-91ac-69bef2b5e734')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-5c8a71fb-1746-44cc-91ac-69bef2b5e734 button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-5c8a71fb-1746-44cc-91ac-69bef2b5e734');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "]},"metadata":{},"execution_count":13}]},{"cell_type":"markdown","source":["보수 정당: 1 조선일보, 중앙일보\n","\n","진보 정당: 0 한겨례, 경향"],"metadata":{"id":"8Z3KMW6Nt69w"}},{"cell_type":"code","source":["df.loc[(df['news'] == '조선일보') | (df['news'] == '중앙일보'), 'news'] = 1"],"metadata":{"id":"yXKxZKgiuGY3","executionInfo":{"status":"ok","timestamp":1673954024874,"user_tz":-540,"elapsed":6,"user":{"displayName":"송지빈","userId":"11346694006770834807"}}},"execution_count":14,"outputs":[]},{"cell_type":"code","source":["df.loc[(df['news'] == '한겨레') | (df['news'] == '경향'), 'news'] = 0\n","df"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":424},"id":"47lXXwWuxxyQ","executionInfo":{"status":"ok","timestamp":1673954025373,"user_tz":-540,"elapsed":29,"user":{"displayName":"송지빈","userId":"11346694006770834807"}},"outputId":"5cc80d15-912e-4fae-f991-0d5dcc94ea3a"},"execution_count":15,"outputs":[{"output_type":"execute_result","data":{"text/plain":["                                      title news  \\\n","0         윤 대통령 “북 무인기 한 대 왔으면 우린 2~3대 보내라”    1   \n","1               노웅래 체포안 부결...與 \"이재명 방탄 예고편\"    1   \n","2        이재명 때린 17년전 이재명? '지자체 부정부패' 논문 재조명    1   \n","3    [단독] TBS 직원 10명중 6명 \"김어준 방송, 중립적이지 않다\"    1   \n","4        미사일 안쏘고 韓 흔든 北…대박난 '회색지대 도발' 더 세진다    1   \n","..                                      ...  ...   \n","395    43%가 ‘사표’…“소선거구제는 썩은 그릇에 국물 조금 붓는 것”    0   \n","396         윤 대통령 지지율 41.2%…2주 연속 상승 [리얼미터]    0   \n","397   민주, ‘이재명 수사’ 검사 16명 공개…국힘 “헌법 질서에 도전”    0   \n","398         노란봉투법·양곡관리법·차별금지법…여야 이견 속 해 넘길판    0   \n","399       ‘국민통합’ 꺼내든 정치인 사면…이번에도 국민 공감대는 없다    0   \n","\n","                                           new_article  \n","0    윤석열 대통령 28일 북한 도발 에도 확실하게 응징 보복 라 그것 가장 강력한 수단...  \n","1    저번 주셨는데 뭘 주냐 저번 그거 잘 쓰고 있는데 라고 말 하는 노웅래 민주당 의원...  \n","2    이재명 민주당 대표 성남 FC 후 원금 의혹 관련 해 검찰 수사 받는 가운데 17년...  \n","3    정치 적 편향 논란 끊이지 않던 TBS 교통 방송 라디오 프로그램 김어준 뉴스 공장...  \n","4    북한 대남 도발 날로 교묘해지고 핵 ㆍ 미사일 같은 고 강도 도발 에다 지난 26일...  \n","..                                                 ...  \n","395  2020년 치러진 21 대 총선 참여 한 유권자 2874만 1408 표 가운데 10...  \n","396  윤석열 대통령 국정 지지율 2 주 연속 상승 해 41 대를 기록 했다 리얼미터 미디...  \n","397  민주당 이재명 대표 관련 한 수사 진행 중인 검사 사진 이름 담긴 자료 만들어 전국...  \n","398  여야 지난 24일 638조 7천억원 규모 내년 도 예산안 부수 법안 지각 처리 했지...  \n","399  윤석열 대통령 연말 특별사면 권 행사 앞두고 헌법 보장 된 대통령 사면권 에는 국민...  \n","\n","[400 rows x 3 columns]"],"text/html":["\n","  <div id=\"df-8aa28c59-1645-4026-b4dc-bfe66f735c23\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>title</th>\n","      <th>news</th>\n","      <th>new_article</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>윤 대통령 “북 무인기 한 대 왔으면 우린 2~3대 보내라”</td>\n","      <td>1</td>\n","      <td>윤석열 대통령 28일 북한 도발 에도 확실하게 응징 보복 라 그것 가장 강력한 수단...</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>노웅래 체포안 부결...與 \"이재명 방탄 예고편\"</td>\n","      <td>1</td>\n","      <td>저번 주셨는데 뭘 주냐 저번 그거 잘 쓰고 있는데 라고 말 하는 노웅래 민주당 의원...</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>이재명 때린 17년전 이재명? '지자체 부정부패' 논문 재조명</td>\n","      <td>1</td>\n","      <td>이재명 민주당 대표 성남 FC 후 원금 의혹 관련 해 검찰 수사 받는 가운데 17년...</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>[단독] TBS 직원 10명중 6명 \"김어준 방송, 중립적이지 않다\"</td>\n","      <td>1</td>\n","      <td>정치 적 편향 논란 끊이지 않던 TBS 교통 방송 라디오 프로그램 김어준 뉴스 공장...</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>미사일 안쏘고 韓 흔든 北…대박난 '회색지대 도발' 더 세진다</td>\n","      <td>1</td>\n","      <td>북한 대남 도발 날로 교묘해지고 핵 ㆍ 미사일 같은 고 강도 도발 에다 지난 26일...</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>395</th>\n","      <td>43%가 ‘사표’…“소선거구제는 썩은 그릇에 국물 조금 붓는 것”</td>\n","      <td>0</td>\n","      <td>2020년 치러진 21 대 총선 참여 한 유권자 2874만 1408 표 가운데 10...</td>\n","    </tr>\n","    <tr>\n","      <th>396</th>\n","      <td>윤 대통령 지지율 41.2%…2주 연속 상승 [리얼미터]</td>\n","      <td>0</td>\n","      <td>윤석열 대통령 국정 지지율 2 주 연속 상승 해 41 대를 기록 했다 리얼미터 미디...</td>\n","    </tr>\n","    <tr>\n","      <th>397</th>\n","      <td>민주, ‘이재명 수사’ 검사 16명 공개…국힘 “헌법 질서에 도전”</td>\n","      <td>0</td>\n","      <td>민주당 이재명 대표 관련 한 수사 진행 중인 검사 사진 이름 담긴 자료 만들어 전국...</td>\n","    </tr>\n","    <tr>\n","      <th>398</th>\n","      <td>노란봉투법·양곡관리법·차별금지법…여야 이견 속 해 넘길판</td>\n","      <td>0</td>\n","      <td>여야 지난 24일 638조 7천억원 규모 내년 도 예산안 부수 법안 지각 처리 했지...</td>\n","    </tr>\n","    <tr>\n","      <th>399</th>\n","      <td>‘국민통합’ 꺼내든 정치인 사면…이번에도 국민 공감대는 없다</td>\n","      <td>0</td>\n","      <td>윤석열 대통령 연말 특별사면 권 행사 앞두고 헌법 보장 된 대통령 사면권 에는 국민...</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>400 rows × 3 columns</p>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-8aa28c59-1645-4026-b4dc-bfe66f735c23')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-8aa28c59-1645-4026-b4dc-bfe66f735c23 button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-8aa28c59-1645-4026-b4dc-bfe66f735c23');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "]},"metadata":{},"execution_count":15}]},{"cell_type":"code","source":["df.news.unique()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"K0kGL5ZIw0pn","executionInfo":{"status":"ok","timestamp":1673954033378,"user_tz":-540,"elapsed":409,"user":{"displayName":"송지빈","userId":"11346694006770834807"}},"outputId":"81eccf3d-a558-4358-8bdd-fb6984d4c3ab"},"execution_count":16,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([1, 0], dtype=object)"]},"metadata":{},"execution_count":16}]},{"cell_type":"code","source":["df['news'] = df['news'].astype(int)\n","df['news']"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"_NXcStwrb3qj","executionInfo":{"status":"ok","timestamp":1673954091950,"user_tz":-540,"elapsed":305,"user":{"displayName":"송지빈","userId":"11346694006770834807"}},"outputId":"c9957fdd-e61f-49bc-e21a-a53203677124"},"execution_count":22,"outputs":[{"output_type":"execute_result","data":{"text/plain":["0      1\n","1      1\n","2      1\n","3      1\n","4      1\n","      ..\n","395    0\n","396    0\n","397    0\n","398    0\n","399    0\n","Name: news, Length: 400, dtype: int64"]},"metadata":{},"execution_count":22}]},{"cell_type":"markdown","source":["## Train set / Test set으로 나누기"],"metadata":{"id":"WleGsMVNd9Nm"}},{"cell_type":"code","source":["# train dataset\n","from sklearn.model_selection import train_test_split\n","\n","X_train, X_test, y_train, y_test = train_test_split(df[['title', 'new_article']], df['news'])\n","# X_train, X_valid, y_train, y_valid = train_test_split(X_train_full, y_train_full)\n","\n","train = pd.concat([X_train,y_train],1)\n","test = pd.concat([X_test,y_test],1)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Zqx-Q5zRUHqM","executionInfo":{"status":"ok","timestamp":1673954099496,"user_tz":-540,"elapsed":375,"user":{"displayName":"송지빈","userId":"11346694006770834807"}},"outputId":"f5694d42-dba8-4465-911d-881dff73e9e5"},"execution_count":23,"outputs":[{"output_type":"stream","name":"stderr","text":["<ipython-input-23-505e853eba5d>:7: FutureWarning: In a future version of pandas all arguments of concat except for the argument 'objs' will be keyword-only\n","  train = pd.concat([X_train,y_train],1)\n","<ipython-input-23-505e853eba5d>:8: FutureWarning: In a future version of pandas all arguments of concat except for the argument 'objs' will be keyword-only\n","  test = pd.concat([X_test,y_test],1)\n"]}]},{"cell_type":"markdown","source":["# Train set 전처리"],"metadata":{"id":"iWMaBMgrewnJ"}},{"cell_type":"markdown","source":["## 각 문장마다 [CLS]와 [SEP]를 붙여주기"],"metadata":{"id":"RVJ-bmsieyo-"}},{"cell_type":"code","source":["sentences = [\"[CLS] \" + str(s) + \" [SEP]\" for s in train.new_article]\n","sentences[:5]"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"9py4IU-hfDKj","executionInfo":{"status":"ok","timestamp":1673954100878,"user_tz":-540,"elapsed":21,"user":{"displayName":"송지빈","userId":"11346694006770834807"}},"outputId":"9e6a4046-ce2b-4139-c9d0-fcb750a83482"},"execution_count":24,"outputs":[{"output_type":"execute_result","data":{"text/plain":["['[CLS] 이재명 민주당 대표 29일 김근태 전 열린 우리당 의장 11 주기 추모 미사 참석 해 수십 간 의장 님 같은 분 희생 고통 통해 서 어렵게 쌓아 올린 민주주의 사방 무너지고 고 말 했다 대표 는 날 오전 11시 서울 도봉구 창동 성당 열린 추모 미사 나라 근간 인 민생 경제 백 척 간 두 위기 이고 한반도 다시 공포 그림자 짙게 드리워지고 위기 아닌 곳 찾기 힘들다 면서 이같이 말 했다 대표 는 공정 원칙 상실한 권력 폭주 강력하게 맞서겠다 면서 윤석열 정부 겨냥 했다 는 의장 님 께서는 누군가 해야 김근태 하겠다 말씀 자주 주셨다 면서 이제 김근태 되겠다 누군가 해야 이재명 민주당 앞장서겠다 고 밝혔다 앞서 대표 는 날 국회 열린 검찰 인권 침해 수사 문제점 제도 적 대책 마련 위 한 토론회 에서도 윤석열 정권 검찰 공익 대변자 라는 책무 망각 하고 민주주의 파괴 하는 도구로 전락 했다 고 주장 했다 대표 는 공 정성 완전히 상실한 정권 폭주 결연히 맞서야 한다 면서 일부 검찰 행태 매우 불공정 하고 편향 되고 조작 서슴지 않는 범죄 적 행위 행 하고 고 말 했다 대표 는 토론회 직후 1월 첫째 주 검찰 출석 하는 게 맞느냐 는 기자 질문 에는 대통령 가족 대한 수사 는 하는지도 관심 가져주기 바란다 고 응수 했다 대표 는 새해 첫날 경남 김해 봉하마을 찾아 노무현 전 대통령 묘역 참배 하고 날인 2일 경남 양산 평산 마을 찾아 문재인 전 대통령 방한 다 문재인 정부 인사 검찰 수사 선상 오른 가운데 대표 문 전 대통령 검찰 규탄 하는 메시지 낼 지 관심 모인다 박찬 대 민주당 의원 은 날 MBC 라디오 김종배 시선집중 문 전 대통령 이나 대표 도 검찰 독재 공화국 내 지금 엄청난 탄압 받고 있는 상황 이라면서 현 정세 대한 의견 은 서로 나눌 수 는 있지 않을까 생각 한다 고 말 했다 검찰 소환 통보 받은 대표 문 전 대통령 만나 정부 비판 하면 지 지층 결집 효과 있을 이라는 분석 나온다 대표 는 날 새해 맞아 국민 당원 보낸 연하 장 야당 파괴 정치 보복 민주주의 는 질식 해가고 고 했다 대표 는 성남 FC 후 원금 의혹 특정 범죄 가중 처벌 법 상 3 뇌물 공 혐의 받고 검찰 은 대표 성남시장 재임 할 당시 기업 으로부터 성남 FC 후 원금 받는 대가 기업 특혜 제공 했다고 보고 검찰 은 대표 12월 28일 출석 요청 했으나 대표 일정 이유 불발 됐다 수원지검 성남 지청 은 날 문자 공보 통해 12월 27일 오후 2시 경 변호인 검찰 연락 하여 검찰 출석 요구 한 12월 28일 출석 은 어렵다고 공식 적 답변 해왔다 며 최종 적 검찰 은 출석 최초 요 구일 보다 2 주 연기 하는 하고 1월 10 12일 중 가능한 날 알려 달라 고 요청 했고 현재 답변 기다리고 있는 중 이라고 밝혔다 [SEP]',\n"," '[CLS] 윤석열 대통령 국정 운영 지지도 직전 조사 같은 34 유지 했다는 조사 결과 29일 나왔다 엠브레인 퍼블릭 케이스 탯 리서치 코리아 리서치 한국 리서치 지난 26 28일 전국 성인 1010 명 대상 조사 신뢰 수준 95 표본 오차 3 1 포인트 한 전국 지표조사 NBS 결과 윤 대통령 국정 운영 잘 하고 는 긍정 평가 는 34 잘못 하고 는 부정 평가 는 56 였다 직전 조사 인 2 주 전과 같은 수치 다 국정 운영 긍정 적 평가 하는 이유 는 결단 력 있어서 33 가장 많았고 공정하고 정의 워 서 30 유능하고 합리 적 11 약속 한 공약 잘 실천 해서 7 뒤 반면 부정 적 평가 하는 이유 는 독단 적 이고 일방 적 34 가장 많았고 경험 능력 부족해서 30 적합하지 않은 인물 고위 직 기용 해서 11 순 정당 지지도 는 국민 힘 32 민주당 28 정의당 5 였다 지지 정당 없다고 밝힌 비율 은 33 나타났다 2 주 전보 다 국민 힘 은 4 포인트 민주당 은 2 포인트 하락 했다 한편 정부 실내 마스크 착용 의무 해제 검토 하고 있는 가운데 실내 마스크 전면 해제 찬성 한다는 응답 은 41 반대 는 57 조사 됐다 18 29 살 사이 에서는 찬성 비율 60 상대 적 높게 나왔다 자세한 내용 은 중앙 여론조사 심의 위원회 누리집 참고 하면 된다 [SEP]',\n"," '[CLS] 국방부 는 30일 국내 기술 개발 한 고체 추진 우주발사체 시험 비행 성공했다고 밝혔다 지난 3월 성능 검증 위 한 첫 시험 발사 성공했다고 밝힌 지 9 개월 만이 다 발사체 시험 예고 없이 이뤄지면서 전국 각지 발사체 궤 적 목격 한 시민 제보 이어졌다 국방부 대변인 실 은 날 우주 안보 경 시대 맞춰 독자 적 우주 기반 감시 정찰 분야 국방력 강화 위해 고체 연료 추진 방식 우주발사체 비행 시험 했다 고 밝혔다 국방부 는 이어 비행 시험 은 지난 3월 30일 비행 시험 후속 시험 향후 간 개발 과정 거쳐 성과 내 도록 하겠다 며 군 은 우주 포함 한 국방력 강화 계속 매진 하겠다 고 했다 날 발사체 는 목표 했던 고도 450 km 도달 한 알려졌다 정부 고위 관계자 는 통화 오늘 시험 목표 한 성공 적 이뤄졌다 고 말 했다 고체 연료 기반 하는 추진 기관 은 소형 위성 이나 초소 형 위성 지구 저궤도 올릴 수 있는 우주 발사체 사용 된다 개발 최종 성공하면 군 감시 정찰 강화 국내 우주 산업 활성화 기여 할 정부 는 보고 고체 연료 추진 기관 은 액체 연료 사용 하는 보다 가격 상대 적 저렴하고 구조 간단하다 때문 대량생산 신속한 발사 가능하다 한 미 미사일 지침 은 고체 연료 기반 발사체 사용 제한 해왔지만 지침 지난해 5월 한 미 정상회담 계기 종료 되면서 국방부 국방 과학 연구소 ADD 개발 속도 붙었다 국방부 는 앞서 지난 3월 30일 국내 기술 개발 한 고체 추진 우주발사체 첫 시험 발사 성공했다 시험 발사 에서는 우주발사체 필수 기술 인 대형 고체 추진 기관 페어 링 분리 단 분리 상단 부 자세 제어 기술 검증 이뤄졌다 국방부 는 당시 시험 발사 성공 밝히며 최근 북한 모라토리엄 스스로 파기 하는 대륙간탄도미사일 ICBM 발사 하는 매우 엄중한 시기 고체 추진 우주발사체 시험 발사 성공 은 군 독자 적 우주 기반 감시 정찰 분야 국방력 강화 있어 중요한 이정표 라고 의미 부여 한 바 윤석열 대통령 은 전날 ADD 방문 해 최근 북한 무인기 영공 침범 관련 해 평화 얻기 위 해서는 압도 적 우월한 전쟁 준비 해야 한다 면서 군 필요 하는 비 대칭 전력 조기 확보 될 수 있도록 각고 노력 해 달라 고 당부 했다 군 당국 은 윤 대통령 날 시험 비행 계획 미리 보고 한 전해졌다 날 발사 는 최근 북한 잇 딴 도발 정찰위성 개발 막바지 이르렀다 고 발표 한 무관 치 않아 보인다 대응 해 한국 군 정찰위성 개발 상황 알리면서 견제구 날린 해석 된다 북한 은 지난 19일 조선 중앙 통신 통해 북한 국가 우주개발 국 정찰위성 개발 최종 단계 중요 시험 했다고 공개 한 바 북한 은 군 정찰위성 장 착할 촬영 기구 찍었다는 서울 인천 사진 공개 내년 4월 군사 정찰위성 1 호기 준비 마칠 이라고 했다 국방부 는 우주발사체 시험 계획 대해 사전 알리 지 않았다 날 오후 6시 쯤부터 전국 각지 시민 사전 정보 없이 상공 발사체 궤 적 추정 되는 섬광 목격 했다 소방청 경찰 따르면 오후 6시 9분 하늘 보니 미사일 같은 게 지나간 는 신고 접수 됐다 날 소방 당국 접수 된 신고건 수 는 총 412 건 이다 서울 48 건 경기 118 건 강원 99 건 인천 25 건 충북 25 건 충남 26 건 경북 24 건 경남 22 건 전남 6 건 전국 각지 신고 이뤄졌다 앞서 북한 무인기 지난 26일 서울 상공 침범 한 상황 시민 불안 은 컸다 시민 언론사 이를 제보 하고 사회 관계 망 서비스 SNS 공개 하는 소동 발생 한 뒤 국방부 는 시험 비행 성공 사실 밝혔다 국방부 는 관련 해 비행 시험 전 발사 경로 관련 있는 영공 해상 안전 대한 조치 하였으나 군사 보안 상의 문제 인해 모든 국민 께 사전 보고 드리지 못 했다 고 밝혔다 [SEP]',\n"," '[CLS] 국민 힘 중국 관련 현안 강경 발언 쏟아내고 중국 발 코로나 19 재 확산 위기 강력 대응 주문 하는 한편 한국 내 중국 비밀경찰 서 의혹 대해 서도 비판 목소리 키우고 주호영 원내대표 는 30일 원 내 대책 회의 코로나 처음 우리나라 확산 될 전문가 7 차례 걸쳐서 중국 발 입국 막는 게 최선 방법 이라고 했지만 문재인 정부 는 말 받아들이지 않아 창궐 했다 며 지난번 실패 거울 삼아 에는 중국 발 코로나 확산 실패 없도록 단단히 대응 해달라 고 말 했다 정부 는 날 중국 발 입국 자의 입국 코로나 19 유전자 증폭 PCR 검사 의무 화 중국 발 항공기 추가 증편 잠정 중단 인천공항 도착 지 일원화 중국인 단기 비자 제한 중국 발 코로나 확산 방지 대책 발표 했다 주 원내대표 는 대해 나라 보다 더 강한 대책 이라고 강조 했다 전날 중국 외교부 각국 방역 조치 는 각국 국민 차별 없어야 한다 는 공식 입장 발표 했지만 당 정이 아랑곳 하지 않고 한 목소리 선제 적 대응 착수 한 이다 전날 국민 힘 내부 에선 중국인 여행자 입국 대한 정부 대응 요구 하는 목소리 컸다 당권 주자 꼽히는 유승민 전 의원 페이스북 중국 정부 코로나 봉쇄 풀 고 확 진자 통계 발표 도 중단 한 이후 감염 는 폭증 하고 있고 한국 행 여행객 도 증가 할 라며 미국 일본 인도 이탈리아 여러 나라 중국 발 입국 대한 코로나 전수 검사 조치 강화하고 는 글 올렸다 정진석 국민 힘 비상 대책 위원 장이 29일 오전 서울 여의도 국회 열린 비 대위 회의 발언 하고 장진영 기자 민감한 외교 문제 비화 할 수 있는 중국 비밀경찰 서 의혹 대해 서도 국민 힘 은 단호 한 입장 취하 고 정진석 비상 대책 위원장 은 전날 비 대위 회의 중국 단체 반체제 인사 감시 탄압 활동 은 국내법 저촉 된다 며 중국 당국 사실관계 성의 있게 확인 해서 국민 납득 할 수 있도록 소상히 설명 해줄 요청 한다 고 말 했다 중국 한국 포함 한 53 국 102 개 비밀 경찰서 운영 중 이라고 폭로 한 국제 인권 단체 세이프 가드 디펜더 스 보고서 내용 인용 한 이다 외 교통 여권 관계자 는 여당 비대 위원 장이 시점 비밀 경찰서 이슈 화 한 은 북한 무차별 대남 도발 팔짱 만 끼 고 있는 중국 압박 하기 위 한 외교 메시지 성격 짙다 고 해석 했다 북한 미사일 무인기 전 방위 도발 어가 는 상황 정부 는 중국 대북 역할 론 강조 하고 윤석열 대통령 은 지난달 29일 보도 된 영국 로이터 통신 인터뷰 중국 은 북한 상당한 영향 줄 수 있는 충분한 능력 국제사회 에서의 책무 며 중국 유엔 안전보장 이사회 상임이사국 역할 다 하지 않으면 역내 군사 적 자산 유입 될 이라고 강조 했다 30일 인천공항 여객 터미널 중국 본토 행 기내식 서비스 중단 안 내 되고 뉴스 1 가운데 국내 반중 정서 는 코로나 19 계기 이전 보다 더 커진 양상 이다 미국 외교 전문 매체 디플로 맷 은 중앙 유럽 아시아 연구소 CEIAS 참여 한 국제 연 구진 올해 4 6월 한국인 성인 남녀 1364 명 대상 진행 한 중국 인식 도 조사 응답 자의 81 부정 적 응답 항 택했다 고 최근 보도 했다 조사 대상 56 개국 중 1 위고 2 위 스위스 72 비 해서도 10 포인트 가깝게 높은 수치 였다 일각 에선 책임 있는 여당 인 중국 향 해 할 소리 되 반중 反中 정서 궤 하는 듯 한 느낌 은 주지 말아야 한다는 지적 나오고 정진석 위원장 도 비밀경찰 서 의혹 해명 요청 중국 은 우리나라 1 교역 국 이고 한반도 평화 구축 위 한 파트너 라며 양국 신뢰 관계 더 굳건 히 서기 기대한다 는 말 도 강조 했다 [SEP]',\n"," '[CLS] 계륵 이재명 방탄 그만하고 민주당 스스로 떠나야 국민 힘 반도체 특위 이끌었던 무소속 양 향 의원 은 28일 야당 기재부 반도체 법 핵심 인 조 세 특례 조항 바꿔서 반의 반쪽 만들어 버렸다 면서 국가 미래 땅 에다 묻어 버린 이라고 비판 했다 양 의원 은 날 조선일보 유튜브 배성규 배소 빈 정치 펀치 출연 반도체 특위 여야 정 산학 반도체 지 원 책 논의 하고 만들었는데 도 모르는 사이 여야 원내대표 단 비공식 논의 거쳐 상임 위 협의 과정 도 없이 본회의 올려 버렸다 며 기재부 안대 연말 예산 법안 끼워 넣어 처리 할 일이 아니었다 고 했다 양 의원 은 대기업 은 세액 공제 20 중견 기업 은 25 중소기업 은 30 정도 는 해야 반도체 경쟁 밀리 지 않는다 며 야당 에서도 10 15 30 대안 냈는데 기재부 그것 못 미치는 8 8 16 안 내서 그냥 통과 시켜 버렸다 고 했다 미국 주요 국가 은 세액 공제 25 해주는데 만 8 세액 공제 하는 은 100 m 달리기 50 m 뒤 뛰라는 마찬가지 라는 이다 양 의원 은 외국 기업 은 정부 총알 25 개 받았는데 는 총알 8 개 만 받은 라며 이러고서 국제 경쟁 이기겠느냐 고 했다 서울 뉴스 1 유승 관 기자 추경호 부총리 겸 기획재정부 장관 23일 서울 여의도 국회 열린 401회 국회 임시회 2 차 본회의 조 세 특례 한 법 일부 개정 법률 안 대한 반대 토론 고 자리 이동 하는 양 향 무소속 의원 손 잡고 인사 하고 2022 12 23 뉴스 1 양 의원 은 일부 의원 기재부 부탁 받았는지 갑자기 본회의 법안 찬성 토론 대만 은 세액 공제 작다고 하는데 사실 다르다 며 대만 은 반도체 기업 토지 무상 임대 해 주고 비용 대한 지원 엄청나게 해준다 고 했다 지원 금액 수조 원 달 한다는 이다 양 의원 은 기재부 법인세 3 인하 방안 추진 반도체 기업 대한 세액 공제 는 다 깎아 버렸다 면서 법인세 는 인하 하자면서 세수 감소 이유 반도체 기업 만 세금 혜택 못 주겠다는 은 이율배반 이라고 했다 윤석열 대통령 반도체 대한 대폭 적 지원 약속 했는데 결과 는 정반대 됐다면서 대통령실 조정 역할 문제 있었던 이라고 했다 는 전쟁 터 뛰는 장수 기업 얘기 들어야지 뒤 뒷짐 지고 전쟁 터 바라보기만 하는 관료 말 만 들어서 되겠느냐 며 이제 반도체 특위 시즌 1 끝났지만 시즌 2 잘 못 된 바로잡겠다 고 했다 양 의원 은 이재명 민주당 대표 대해 민주당 가기 도 어렵고 그렇다고 놓 아버 리기 도 힘든 계륵 같은 존재 됐다 면서 계속 비리 혐의 대한 방탄 만 하지 말고 스스로 당 떠나야 한다 고 했다 는 의원 이든 대표 든 측근 구속 되고 구체 적 혐의 제기 되면 스스로 자리 물러나거나 당 나와서 혐의 대한 소명 한 뒤 모든 게 정리 되면 다시 돌아오는 게 그동안 관례 였다 며 대표 는 그러지 못 하느냐 고 비판 했다 양 의원 은 과거 민주당 은 이렇게 망가지지 않았는데 지금 민주당 은 내 들어가서 하기 힘든 정당 돼 버렸다 며 는 이제 민주당 들어가 할 일이 없다 고 했다 는 복당 신청 도 철회 했는데 민주당 김 의겸 대변인 갑자기 복당 심사 해서 불허 결정 했다 고 발표 했다 며 나를 망신 주기 위 한 아니냐 고 했다 이어 대표 검찰 수사 정치 탄압 이라고 하던데 민주당 나를 정치 탄압 한 이라고 했다 [SEP]']"]},"metadata":{},"execution_count":24}]},{"cell_type":"markdown","source":["## 서브워드 토크나이저: WordPiece"],"metadata":{"id":"4jo99b2dkspr"}},{"cell_type":"code","source":["# 샘플 토크나이징\n","import pandas as pd\n","from transformers import BertTokenizer\n","\n","tokenizer = BertTokenizer.from_pretrained(\"bert-base-multilingual-cased\", do_lower_case=False)\n","result = tokenizer.tokenize('안녕하세요')\n","print(result)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":131,"referenced_widgets":["2354776689524649af452cddee4d2e7c","7153528d813a4364a217b69817a437a1","e234edcb20114c7b9e744eeed3b5cdb6","765a3f1c6ab04fcfbcd8b311e967e95f","adb8e06445464861ba8fd0a0522746e5","b88d1f9880ca4f45bd3c844504ea067d","68ed0e3bbbd74c7aa671524bdb8c3887","0fc4557429fb4f61820063293c6fb457","8eb3cef9277048c5be8c6964111227f5","a43913d7090f497ea101dda06033fec3","d9ac8a134509439f95bcf8e976a99d75","ad7431ef9e5b4590a513493ee0d394a3","a2357f566d8b48f4afd522b433685400","db30274f54d645bebc7f8ac70fa94e4b","7325ced1f3a443a2b97f0c0080a335bf","0df013c1496d4260a560a087624ca56f","94785e9dcf1e469e93cc78dd1da4e8b2","7e978144eb4e4a14b7a5e0ecb905dcb1","afe31579b16b4ca981dc8b452a1becc5","c62718e5e495420fb66fb94c5b97cee8","082c2014f95049529e7a0126313d37c0","9e9641cb2b434d76ad992afaae5156f3","aee256b70ef44fe8af0459c64b67c05f","6ab77e1f110248c1947b359babaa5e7a","649e68cad67a464f9f2b5998ef9fc6e1","96275751c25a4da4ba5a267a31350531","7372f77446e44bf09e22d90cf98387b2","a1f72655ee1547ac9a2fc097d1691d99","e4e6837ff87244688ca8f036846229a1","8084e7110a6c4ad586c0dde24192a7f0","74e28e1eecd34291bc96dc6ec7e03f48","541c56e8530d4185a798e7cd73d5fe98","4a257cffacdc4559bbbff3e8dad0b3b9"]},"id":"tr8gMKuClGLZ","executionInfo":{"status":"ok","timestamp":1673954105564,"user_tz":-540,"elapsed":2098,"user":{"displayName":"송지빈","userId":"11346694006770834807"}},"outputId":"5e74c06f-7b79-4e49-fd42-df3521bc592c"},"execution_count":25,"outputs":[{"output_type":"display_data","data":{"text/plain":["Downloading:   0%|          | 0.00/996k [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"2354776689524649af452cddee4d2e7c"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Downloading:   0%|          | 0.00/29.0 [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ad7431ef9e5b4590a513493ee0d394a3"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Downloading:   0%|          | 0.00/625 [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"aee256b70ef44fe8af0459c64b67c05f"}},"metadata":{}},{"output_type":"stream","name":"stdout","text":["['안', '##녕', '##하', '##세', '##요']\n"]}]},{"cell_type":"code","source":["# 전체 데이터에 토크나이징 수행\n","tokenizer = BertTokenizer.from_pretrained('bert-base-multilingual-cased', do_lower_case=False)\n","tokenized_texts = [tokenizer.tokenize(s) for s in sentences]"],"metadata":{"id":"X-kE8PwurB0P","executionInfo":{"status":"ok","timestamp":1673954106823,"user_tz":-540,"elapsed":1269,"user":{"displayName":"송지빈","userId":"11346694006770834807"}}},"execution_count":26,"outputs":[]},{"cell_type":"code","source":["# 토크나이징 잘 되었는지 확인하기\n","print(sentences[0])  #토크나이징 전\n","print(tokenized_texts[0]) #토크나이징 후"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"xgDk8dr6rPEM","executionInfo":{"status":"ok","timestamp":1673954106825,"user_tz":-540,"elapsed":17,"user":{"displayName":"송지빈","userId":"11346694006770834807"}},"outputId":"6265bd3f-9e90-4c83-a15a-a333aa78566f"},"execution_count":27,"outputs":[{"output_type":"stream","name":"stdout","text":["[CLS] 이재명 민주당 대표 29일 김근태 전 열린 우리당 의장 11 주기 추모 미사 참석 해 수십 간 의장 님 같은 분 희생 고통 통해 서 어렵게 쌓아 올린 민주주의 사방 무너지고 고 말 했다 대표 는 날 오전 11시 서울 도봉구 창동 성당 열린 추모 미사 나라 근간 인 민생 경제 백 척 간 두 위기 이고 한반도 다시 공포 그림자 짙게 드리워지고 위기 아닌 곳 찾기 힘들다 면서 이같이 말 했다 대표 는 공정 원칙 상실한 권력 폭주 강력하게 맞서겠다 면서 윤석열 정부 겨냥 했다 는 의장 님 께서는 누군가 해야 김근태 하겠다 말씀 자주 주셨다 면서 이제 김근태 되겠다 누군가 해야 이재명 민주당 앞장서겠다 고 밝혔다 앞서 대표 는 날 국회 열린 검찰 인권 침해 수사 문제점 제도 적 대책 마련 위 한 토론회 에서도 윤석열 정권 검찰 공익 대변자 라는 책무 망각 하고 민주주의 파괴 하는 도구로 전락 했다 고 주장 했다 대표 는 공 정성 완전히 상실한 정권 폭주 결연히 맞서야 한다 면서 일부 검찰 행태 매우 불공정 하고 편향 되고 조작 서슴지 않는 범죄 적 행위 행 하고 고 말 했다 대표 는 토론회 직후 1월 첫째 주 검찰 출석 하는 게 맞느냐 는 기자 질문 에는 대통령 가족 대한 수사 는 하는지도 관심 가져주기 바란다 고 응수 했다 대표 는 새해 첫날 경남 김해 봉하마을 찾아 노무현 전 대통령 묘역 참배 하고 날인 2일 경남 양산 평산 마을 찾아 문재인 전 대통령 방한 다 문재인 정부 인사 검찰 수사 선상 오른 가운데 대표 문 전 대통령 검찰 규탄 하는 메시지 낼 지 관심 모인다 박찬 대 민주당 의원 은 날 MBC 라디오 김종배 시선집중 문 전 대통령 이나 대표 도 검찰 독재 공화국 내 지금 엄청난 탄압 받고 있는 상황 이라면서 현 정세 대한 의견 은 서로 나눌 수 는 있지 않을까 생각 한다 고 말 했다 검찰 소환 통보 받은 대표 문 전 대통령 만나 정부 비판 하면 지 지층 결집 효과 있을 이라는 분석 나온다 대표 는 날 새해 맞아 국민 당원 보낸 연하 장 야당 파괴 정치 보복 민주주의 는 질식 해가고 고 했다 대표 는 성남 FC 후 원금 의혹 특정 범죄 가중 처벌 법 상 3 뇌물 공 혐의 받고 검찰 은 대표 성남시장 재임 할 당시 기업 으로부터 성남 FC 후 원금 받는 대가 기업 특혜 제공 했다고 보고 검찰 은 대표 12월 28일 출석 요청 했으나 대표 일정 이유 불발 됐다 수원지검 성남 지청 은 날 문자 공보 통해 12월 27일 오후 2시 경 변호인 검찰 연락 하여 검찰 출석 요구 한 12월 28일 출석 은 어렵다고 공식 적 답변 해왔다 며 최종 적 검찰 은 출석 최초 요 구일 보다 2 주 연기 하는 하고 1월 10 12일 중 가능한 날 알려 달라 고 요청 했고 현재 답변 기다리고 있는 중 이라고 밝혔다 [SEP]\n","['[CLS]', '이', '##재', '##명', '민', '##주', '##당', '대', '##표', '29일', '김', '##근', '##태', '전', '열린', '우', '##리', '##당', '의', '##장', '11', '주', '##기', '추', '##모', '미', '##사', '참', '##석', '해', '수', '##십', '간', '의', '##장', '님', '같은', '분', '희', '##생', '고', '##통', '통해', '서', '어', '##렵', '##게', '쌓', '##아', '올', '##린', '민', '##주', '##주의', '사', '##방', '무', '##너', '##지고', '고', '말', '했다', '대', '##표', '는', '날', '오', '##전', '11', '##시', '서울', '도', '##봉', '##구', '창', '##동', '성', '##당', '열린', '추', '##모', '미', '##사', '나', '##라', '근', '##간', '인', '민', '##생', '경', '##제', '백', '척', '간', '두', '위', '##기', '이', '##고', '한', '##반', '##도', '다시', '공', '##포', '그', '##림', '##자', '짙', '##게', '드', '##리', '##워', '##지고', '위', '##기', '아닌', '곳', '찾', '##기', '힘', '##들', '##다', '면', '##서', '이', '##같', '##이', '말', '했다', '대', '##표', '는', '공', '##정', '원', '##칙', '상', '##실', '##한', '권', '##력', '폭', '##주', '강', '##력', '##하게', '맞', '##서', '##겠', '##다', '면', '##서', '윤', '##석', '##열', '정', '##부', '겨', '##냥', '했다', '는', '의', '##장', '님', '께', '##서는', '누', '##군', '##가', '해', '##야', '김', '##근', '##태', '하', '##겠', '##다', '말', '##씀', '자', '##주', '주', '##셨', '##다', '면', '##서', '이', '##제', '김', '##근', '##태', '되', '##겠', '##다', '누', '##군', '##가', '해', '##야', '이', '##재', '##명', '민', '##주', '##당', '앞', '##장', '##서', '##겠', '##다', '고', '밝혔다', '앞', '##서', '대', '##표', '는', '날', '국', '##회', '열린', '검', '##찰', '인', '##권', '침', '##해', '수', '##사', '문', '##제', '##점', '제', '##도', '적', '대', '##책', '마', '##련', '위', '한', '토', '##론', '##회', '에서', '##도', '윤', '##석', '##열', '정', '##권', '검', '##찰', '공', '##익', '대', '##변', '##자', '라는', '책', '##무', '망', '##각', '하고', '민', '##주', '##주의', '파', '##괴', '하는', '도', '##구', '##로', '전', '##락', '했다', '고', '주', '##장', '했다', '대', '##표', '는', '공', '정', '##성', '완전히', '상', '##실', '##한', '정', '##권', '폭', '##주', '결', '##연', '##히', '맞', '##서', '##야', '한다', '면', '##서', '일부', '검', '##찰', '행', '##태', '매우', '불', '##공', '##정', '하고', '편', '##향', '되고', '조', '##작', '서', '##슴', '##지', '않는', '범', '##죄', '적', '행', '##위', '행', '하고', '고', '말', '했다', '대', '##표', '는', '토', '##론', '##회', '직', '##후', '1월', '첫', '##째', '주', '검', '##찰', '출', '##석', '하는', '게', '맞', '##느', '##냐', '는', '기자', '질', '##문', '에', '##는', '대통령', '가', '##족', '대한', '수', '##사', '는', '하는', '##지', '##도', '관', '##심', '가', '##져', '##주', '##기', '바', '##란', '##다', '고', '응', '##수', '했다', '대', '##표', '는', '새', '##해', '첫', '##날', '경', '##남', '김', '##해', '봉', '##하', '##마', '##을', '찾', '##아', '노', '##무', '##현', '전', '대통령', '묘', '##역', '참', '##배', '하고', '날', '##인', '2일', '경', '##남', '양', '##산', '평', '##산', '마', '##을', '찾', '##아', '문', '##재', '##인', '전', '대통령', '방', '##한', '다', '문', '##재', '##인', '정', '##부', '인', '##사', '검', '##찰', '수', '##사', '선', '##상', '오', '##른', '가운데', '대', '##표', '문', '전', '대통령', '검', '##찰', '규', '##탄', '하는', '메', '##시', '##지', '낼', '지', '관', '##심', '모', '##인', '##다', '박', '##찬', '대', '민', '##주', '##당', '의', '##원', '은', '날', 'MBC', '라디오', '김', '##종', '##배', '시', '##선', '##집', '##중', '문', '전', '대통령', '이', '##나', '대', '##표', '도', '검', '##찰', '독', '##재', '공', '##화', '##국', '내', '지', '##금', '엄', '##청', '##난', '탄', '##압', '받고', '있는', '상', '##황', '이라', '##면서', '현', '정', '##세', '대한', '의', '##견', '은', '서로', '나', '##눌', '수', '는', '있', '##지', '않', '##을', '##까', '생', '##각', '한다', '고', '말', '했다', '검', '##찰', '소', '##환', '통', '##보', '받은', '대', '##표', '문', '전', '대통령', '만', '##나', '정', '##부', '비', '##판', '하', '##면', '지', '지', '##층', '결', '##집', '효', '##과', '있을', '이라는', '분', '##석', '나', '##온', '##다', '대', '##표', '는', '날', '새', '##해', '맞', '##아', '국', '##민', '당', '##원', '보', '##낸', '연', '##하', '장', '야', '##당', '파', '##괴', '정', '##치', '보', '##복', '민', '##주', '##주의', '는', '질', '##식', '해', '##가', '##고', '고', '했다', '대', '##표', '는', '성', '##남', 'FC', '후', '원', '##금', '의', '##혹', '특', '##정', '범', '##죄', '가', '##중', '처', '##벌', '법', '상', '3', '뇌', '##물', '공', '혐', '##의', '받고', '검', '##찰', '은', '대', '##표', '성', '##남', '##시', '##장', '재', '##임', '할', '당시', '기', '##업', '으로', '##부터', '성', '##남', 'FC', '후', '원', '##금', '받', '##는', '대', '##가', '기', '##업', '특', '##혜', '제', '##공', '했다', '##고', '보고', '검', '##찰', '은', '대', '##표', '12월', '28일', '출', '##석', '요', '##청', '했', '##으나', '대', '##표', '일', '##정', '이', '##유', '불', '##발', '됐', '##다', '수', '##원', '##지', '##검', '성', '##남', '지', '##청', '은', '날', '문', '##자', '공', '##보', '통해', '12월', '27일', '오', '##후', '2', '##시', '경', '변', '##호', '##인', '검', '##찰', '연', '##락', '하여', '검', '##찰', '출', '##석', '요', '##구', '한', '12월', '28일', '출', '##석', '은', '어', '##렵', '##다고', '공식', '적', '답', '##변', '해', '##왔다', '며', '최', '##종', '적', '검', '##찰', '은', '출', '##석', '최', '##초', '요', '구', '##일', '보다', '2', '주', '연', '##기', '하는', '하고', '1월', '10', '12일', '중', '가', '##능한', '날', '알', '##려', '달', '##라', '고', '요', '##청', '했', '##고', '현재', '답', '##변', '기', '##다', '##리고', '있는', '중', '이라고', '밝혔다', '[SEP]']\n"]}]},{"cell_type":"code","source":["# 문장의 최대 시퀀스를 설정하여 정수 인코딩과 제로 패딩을 수행해준다.\n","MAX_LEN = 128 #최대 시퀀스 길이 설정\n","# 정수 인코딩\n","input_ids = [tokenizer.convert_tokens_to_ids(x) for x in tokenized_texts]\n","# 제로 패딩\n","input_ids = pad_sequences(input_ids, maxlen=MAX_LEN, dtype=\"long\", truncating=\"post\", padding=\"post\")"],"metadata":{"id":"F7GwcHa8rW8j","executionInfo":{"status":"ok","timestamp":1673954107207,"user_tz":-540,"elapsed":392,"user":{"displayName":"송지빈","userId":"11346694006770834807"}}},"execution_count":28,"outputs":[]},{"cell_type":"code","source":["input_ids[7]"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"VqHHaTOyrnTv","executionInfo":{"status":"ok","timestamp":1673954107874,"user_tz":-540,"elapsed":11,"user":{"displayName":"송지빈","userId":"11346694006770834807"}},"outputId":"2147dc79-de53-4632-f18a-1ca1bb8793ae"},"execution_count":29,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([   101,   6631,   9986,  80331,  11102,   9069,  11287,   9130,\n","        11513,   7908,   3476,  70672,   9323,  48036,  58466,   8933,\n","        13890,   9758,  51431,   9954,  89045,  78123,   9638,  37819,\n","         9519, 119285,   9732,   9318,  61250,   9435,  23466,   8872,\n","         9287,  16985,  72087,   9901,  12092,   9559,  12092,   8885,\n","        82512,   9574, 118782,  17360,   9095,  14646,   9960,  34951,\n","        18471,   9706,  66815,   9626,  17360,  10462,   9405,  24989,\n","         9657,  73380,   9034, 119007,   9632,  10017,  27023,  67527,\n","        10739,  39218, 103611,    122,   9565,  21711,   9043,   9583,\n","        14523,  67313,   8985,  12030,  56047,   9366,  11102,   9095,\n","        14523,   9414,   9059,  41521,  12692,   9847,  12092,  22458,\n","        12945,  18392,  23032,  11274,  11517,   9323,  12945,   9954,\n","         9083,  33378,   9379,  33323,  23622,   9565,  21928,   9632,\n","         9059,  20309,   9954,   9069, 119187,   9949,  48549,  17138,\n","         8853,  20626,  23622,   9538,  21928,   9632,   9087,  51431,\n","         9694,  24989,   9366,  11102,   9758,  17196,   9952,  30936])"]},"metadata":{},"execution_count":29}]},{"cell_type":"markdown","source":["## 어텐션 마스크\n","- 0 값을 가지는 패딩 토큰에 대해서 어텐션 연산을 불필요하게 수행하지 않도록 단어와 패딩 토큰을 구분할 수 있게 알려주는 것"],"metadata":{"id":"nHsGDeOqrrnw"}},{"cell_type":"code","source":["attention_masks = []\n","\n","for seq in input_ids:\n","    seq_mask = [float(i>0) for i in seq]\n","    attention_masks.append(seq_mask)"],"metadata":{"id":"V45JYu8WrtIG","executionInfo":{"status":"ok","timestamp":1673954110235,"user_tz":-540,"elapsed":30,"user":{"displayName":"송지빈","userId":"11346694006770834807"}}},"execution_count":30,"outputs":[]},{"cell_type":"code","source":["print(attention_masks[7])"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"HxaOwXoFs2VS","executionInfo":{"status":"ok","timestamp":1673954110241,"user_tz":-540,"elapsed":28,"user":{"displayName":"송지빈","userId":"11346694006770834807"}},"outputId":"48fe4c6f-b4b0-40f9-e847-848972d40bb3"},"execution_count":31,"outputs":[{"output_type":"stream","name":"stdout","text":["[1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]\n"]}]},{"cell_type":"markdown","source":["## Train set를 훈련셋과 검증셋으로 분리하기\n","어텐션 마스크도 분리!"],"metadata":{"id":"Lz19fy65s9Ii"}},{"cell_type":"code","source":["labels = train['news'].values\n","# labels = labels.astype(np.int)\n","\n","train_inputs, validation_inputs, train_labels, validation_labels = train_test_split(input_ids, labels, random_state=2, test_size=0.1)\n","train_masks, validation_masks, _, _ = train_test_split(attention_masks, input_ids, random_state=2000, test_size=0.1)\n","\n","train_labels.astype('float64')\n","\n","train_inputs = torch.tensor(train_inputs)\n","train_labels = torch.tensor(train_labels)\n","train_masks = torch.tensor(train_masks)\n","validation_inputs = torch.tensor(validation_inputs)\n","validation_labels = torch.tensor(validation_labels)\n","validation_masks = torch.tensor(validation_masks)"],"metadata":{"id":"DNNQb0DYtBhf","executionInfo":{"status":"ok","timestamp":1673954114524,"user_tz":-540,"elapsed":5,"user":{"displayName":"송지빈","userId":"11346694006770834807"}}},"execution_count":32,"outputs":[]},{"cell_type":"code","source":["# 배치 사이즈 32로 설정하고, 입력데이터, 어텐션 마스크, 라벨을 하나의 데이터로 묶어 train_dataloader, validation_dataloader라는 입력 데이터를 생성해준다.\n","batch_size = 32\n","\n","train_data = TensorDataset(train_inputs, train_masks, train_labels)\n","train_sampler = RandomSampler(train_data)\n","train_dataloader = DataLoader(train_data, sampler=train_sampler, batch_size=batch_size)\n","\n","validation_data = TensorDataset(validation_inputs, validation_masks, validation_labels)\n","validation_sampler = SequentialSampler(validation_data)\n","validation_dataloader = DataLoader(validation_data, sampler=validation_sampler, batch_size=batch_size)"],"metadata":{"id":"qvi-Qz6ottsT","executionInfo":{"status":"ok","timestamp":1673954117136,"user_tz":-540,"elapsed":334,"user":{"displayName":"송지빈","userId":"11346694006770834807"}}},"execution_count":33,"outputs":[]},{"cell_type":"markdown","source":["# Test set 전처리"],"metadata":{"id":"fWh9UrScz4cR"}},{"cell_type":"code","source":["sentences = [\"[CLS] \" + str(s) + \" [SEP]\" for s in test.new_article]"],"metadata":{"id":"4xuMORFQ5k1B","executionInfo":{"status":"ok","timestamp":1673954120065,"user_tz":-540,"elapsed":489,"user":{"displayName":"송지빈","userId":"11346694006770834807"}}},"execution_count":34,"outputs":[]},{"cell_type":"code","source":["# [CLS] + 문장 + [SEP]\n","sentences = [\"[CLS] \" + str(sentence) + \" [SEP]\" for sentence in sentences]\n","\n","# 라벨 데이터\n","labels = test['news'].values\n","\n","# Word 토크나이저 토큰화\n","tokenizer = BertTokenizer.from_pretrained('bert-base-multilingual-cased', do_lower_case=False)\n","tokenized_texts = [tokenizer.tokenize(sent) for sent in sentences]\n","\n","# 시퀀스 설정 및 정수 인덱스 변환 & 패딩\n","MAX_LEN = 128\n","input_ids = [tokenizer.convert_tokens_to_ids(x) for x in tokenized_texts]\n","input_ids = pad_sequences(input_ids, maxlen=MAX_LEN, dtype=\"long\", truncating=\"post\", padding=\"post\")\n","\n","# 어텐션 마스크\n","attention_masks = []\n","for seq in input_ids:\n","    seq_mask = [float(i>0) for i in seq]\n","    attention_masks.append(seq_mask)\n","    \n","# 파이토치 텐서로 변환\n","test_inputs = torch.tensor(input_ids)\n","labels = labels.astype(np.int)\n","test_labels = torch.tensor(labels)\n","test_masks = torch.tensor(attention_masks)\n","\n","# 배치 사이즈 설정 및 데이터 설정\n","batch_size = 32\n","test_data = TensorDataset(test_inputs, test_masks, test_labels)\n","test_sampler = RandomSampler(test_data)\n","test_dataloader = DataLoader(test_data, sampler=test_sampler, batch_size=batch_size)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"BisvVuazz6Iv","executionInfo":{"status":"ok","timestamp":1673954139387,"user_tz":-540,"elapsed":1854,"user":{"displayName":"송지빈","userId":"11346694006770834807"}},"outputId":"344d70d6-ab30-4ea8-b6f8-9daac6664365"},"execution_count":35,"outputs":[{"output_type":"stream","name":"stderr","text":["<ipython-input-35-91965f42e0e7>:24: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\n","Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n","  labels = labels.astype(np.int)\n"]}]},{"cell_type":"code","source":["len(test_inputs), len(test_masks), len(test_labels)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Qyruis3V5LWk","executionInfo":{"status":"ok","timestamp":1673954141487,"user_tz":-540,"elapsed":426,"user":{"displayName":"송지빈","userId":"11346694006770834807"}},"outputId":"e713d094-bae6-4733-f625-328434fa3317"},"execution_count":36,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(100, 100, 100)"]},"metadata":{},"execution_count":36}]},{"cell_type":"markdown","source":["# BERT 모델 불러오기"],"metadata":{"id":"dTt1UJWrz_fJ"}},{"cell_type":"code","source":["# GPU 설정\n","if torch.cuda.is_available():    \n","    device = torch.device(\"cuda\")\n","    print('There are %d GPU(s) available.' % torch.cuda.device_count())\n","    print('We will use the GPU:', torch.cuda.get_device_name(0))\n","else:\n","    device = torch.device(\"cpu\")\n","    print('No GPU available, using the CPU instead.')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"pK6EYkZO4JcU","executionInfo":{"status":"ok","timestamp":1673954144194,"user_tz":-540,"elapsed":14,"user":{"displayName":"송지빈","userId":"11346694006770834807"}},"outputId":"30941155-8ca3-487f-ddac-fd0c4439e417"},"execution_count":37,"outputs":[{"output_type":"stream","name":"stdout","text":["There are 1 GPU(s) available.\n","We will use the GPU: Tesla T4\n"]}]},{"cell_type":"code","source":["# pretrain된 BERT 모델을 불러오자\n","model = BertForSequenceClassification.from_pretrained(\"bert-base-multilingual-cased\", num_labels=2)\n","model.cuda()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000,"referenced_widgets":["66850ceb71654cbf817d36655b7bfc89","6fe826ed553e459696b079a73c8cce67","3c582e3a587d42b7a85830423e07ba4a","e25012ded8474f219dd4b5665df3e40c","337eed94ecd44bc1b14ed24f96d02cb5","3249d864625346f4898e981f7bea211e","94b42ae3ab4a4160a2ab236d338610ca","9f6cc3b9ec2a4bdbaced72b523d7b77b","2683b7a846324930be3b71ead3ec4b72","1c4bdfef1ef54454afc4f3aeae95de1e","af093360ead94567a0935a8d5816d6f0"]},"id":"PP4xUGvM4M3N","executionInfo":{"status":"ok","timestamp":1673954164934,"user_tz":-540,"elapsed":19251,"user":{"displayName":"송지빈","userId":"11346694006770834807"}},"outputId":"e429304e-5e82-4ae3-ab85-e95479c06a59"},"execution_count":38,"outputs":[{"output_type":"display_data","data":{"text/plain":["Downloading:   0%|          | 0.00/714M [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"66850ceb71654cbf817d36655b7bfc89"}},"metadata":{}},{"output_type":"stream","name":"stderr","text":["Some weights of the model checkpoint at bert-base-multilingual-cased were not used when initializing BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias']\n","- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-multilingual-cased and are newly initialized: ['classifier.bias', 'classifier.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]},{"output_type":"execute_result","data":{"text/plain":["BertForSequenceClassification(\n","  (bert): BertModel(\n","    (embeddings): BertEmbeddings(\n","      (word_embeddings): Embedding(119547, 768, padding_idx=0)\n","      (position_embeddings): Embedding(512, 768)\n","      (token_type_embeddings): Embedding(2, 768)\n","      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","      (dropout): Dropout(p=0.1, inplace=False)\n","    )\n","    (encoder): BertEncoder(\n","      (layer): ModuleList(\n","        (0): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            (intermediate_act_fn): GELUActivation()\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (1): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            (intermediate_act_fn): GELUActivation()\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (2): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            (intermediate_act_fn): GELUActivation()\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (3): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            (intermediate_act_fn): GELUActivation()\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (4): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            (intermediate_act_fn): GELUActivation()\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (5): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            (intermediate_act_fn): GELUActivation()\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (6): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            (intermediate_act_fn): GELUActivation()\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (7): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            (intermediate_act_fn): GELUActivation()\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (8): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            (intermediate_act_fn): GELUActivation()\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (9): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            (intermediate_act_fn): GELUActivation()\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (10): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            (intermediate_act_fn): GELUActivation()\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (11): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            (intermediate_act_fn): GELUActivation()\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","      )\n","    )\n","    (pooler): BertPooler(\n","      (dense): Linear(in_features=768, out_features=768, bias=True)\n","      (activation): Tanh()\n","    )\n","  )\n","  (dropout): Dropout(p=0.1, inplace=False)\n","  (classifier): Linear(in_features=768, out_features=2, bias=True)\n",")"]},"metadata":{},"execution_count":38}]},{"cell_type":"code","source":["# 하이퍼 파라미터 설정해주기\n","\n","# 옵티마이저\n","optimizer = AdamW(model.parameters(),\n","                  lr = 2e-5, # 학습률(learning rate)\n","                  eps = 1e-8 \n","                )\n","\n","# 에폭수\n","epochs = 4\n","\n","# 총 훈련 스텝 : 배치반복 횟수 * 에폭\n","total_steps = len(train_dataloader) * epochs\n","\n","# 스케줄러 생성\n","scheduler = get_linear_schedule_with_warmup(optimizer, \n","                                            num_warmup_steps = 0,\n","                                            num_training_steps = total_steps)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"VcDf7xWh4SP1","executionInfo":{"status":"ok","timestamp":1673954164935,"user_tz":-540,"elapsed":51,"user":{"displayName":"송지빈","userId":"11346694006770834807"}},"outputId":"dbf21f65-5f79-44f6-9553-e007b36c52cf"},"execution_count":39,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.8/dist-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n","  warnings.warn(\n"]}]},{"cell_type":"markdown","source":["# 모델 학습"],"metadata":{"id":"GjxSHjwx4ckf"}},{"cell_type":"code","source":["# 정확도 계산 함수\n","def flat_accuracy(preds, labels):\n","    \n","    pred_flat = np.argmax(preds, axis=1).flatten()\n","    labels_flat = labels.flatten()\n","\n","    return np.sum(pred_flat == labels_flat) / len(labels_flat)\n","    \n","    \n","# 시간 표시 함수\n","def format_time(elapsed):\n","\n","    # 반올림\n","    elapsed_rounded = int(round((elapsed)))\n","    \n","    # hh:mm:ss으로 형태 변경\n","    return str(datetime.timedelta(seconds=elapsed_rounded))"],"metadata":{"id":"X--eABZ64d8E","executionInfo":{"status":"ok","timestamp":1673945107997,"user_tz":-540,"elapsed":508,"user":{"displayName":"송지빈","userId":"11346694006770834807"}}},"execution_count":160,"outputs":[]},{"cell_type":"code","source":["#랜덤시드 고정\n","seed_val = 42\n","random.seed(seed_val)\n","np.random.seed(seed_val)\n","torch.manual_seed(seed_val)\n","torch.cuda.manual_seed_all(seed_val)\n","\n","#그래디언트 초기화\n","model.zero_grad()\n","\n","# 학습\n","for epoch_i in range(0, epochs):\n","    \n","    # ========================================\n","    #               Training\n","    # ========================================\n","    \n","    print(\"\")\n","    print('======== Epoch {:} / {:} ========'.format(epoch_i + 1, epochs))\n","    print('Training...')\n","\n","    # 시작 시간 설정\n","    t0 = time.time()\n","\n","    # 로스 초기화\n","    total_loss = 0\n","\n","    # 훈련모드로 변경\n","    model.train()\n","        \n","    # 데이터로더에서 배치만큼 반복하여 가져옴\n","    for step, batch in enumerate(train_dataloader):\n","        # 경과 정보 표시\n","        if step % 500 == 0 and not step == 0:\n","            elapsed = format_time(time.time() - t0)\n","            print('  Batch {:>5,}  of  {:>5,}.    Elapsed: {:}.'.format(step, len(train_dataloader), elapsed))\n","\n","        # 배치를 GPU에 넣음\n","        batch = tuple(t.to(device) for t in batch)\n","        \n","        # 배치에서 데이터 추출\n","        b_input_ids, b_input_mask, b_labels = batch\n","\n","        # Forward 수행                \n","        outputs = model(b_input_ids, \n","                        token_type_ids=None, \n","                        attention_mask=b_input_mask, \n","                        labels=b_labels)\n","        \n","        # 로스 구함\n","        loss = outputs[0]\n","\n","        # 총 로스 계산\n","        total_loss += loss.item()\n","\n","        # Backward 수행으로 그래디언트 계산\n","        loss.backward()\n","\n","        # 그래디언트 클리핑\n","        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n","\n","        # 그래디언트를 통해 가중치 파라미터 업데이트\n","        optimizer.step()\n","\n","        # 스케줄러로 학습률 감소\n","        scheduler.step()\n","\n","        # 그래디언트 초기화\n","        model.zero_grad()\n","\n","    # 평균 로스 계산\n","    avg_train_loss = total_loss / len(train_dataloader)            \n","\n","    print(\"\")\n","    print(\"  Average training loss: {0:.2f}\".format(avg_train_loss))\n","    print(\"  Training epcoh took: {:}\".format(format_time(time.time() - t0)))\n","        \n","    # ========================================\n","    #               Validation\n","    # ========================================\n","\n","    print(\"\")\n","    print(\"Running Validation...\")\n","\n","    #시작 시간 설정\n","    t0 = time.time()\n","\n","    # 평가모드로 변경\n","    model.eval()\n","\n","    # 변수 초기화\n","    eval_loss, eval_accuracy = 0, 0\n","    nb_eval_steps, nb_eval_examples = 0, 0\n","\n","    # 데이터로더에서 배치만큼 반복하여 가져옴\n","    for batch in validation_dataloader:\n","        # 배치를 GPU에 넣음\n","        batch = tuple(t.to(device) for t in batch)\n","        \n","        # 배치에서 데이터 추출\n","        b_input_ids, b_input_mask, b_labels = batch\n","        \n","        # 그래디언트 계산 안함\n","        with torch.no_grad():     \n","            # Forward 수행\n","            outputs = model(b_input_ids, \n","                            token_type_ids=None, \n","                            attention_mask=b_input_mask)\n","        \n","        # 로스 구함\n","        logits = outputs[0]\n","\n","        # CPU로 데이터 이동\n","        logits = logits.detach().cpu().numpy()\n","        label_ids = b_labels.to('cpu').numpy()\n","        \n","        # 출력 로짓과 라벨을 비교하여 정확도 계산\n","        tmp_eval_accuracy = flat_accuracy(logits, label_ids)\n","        eval_accuracy += tmp_eval_accuracy\n","        nb_eval_steps += 1\n","\n","    print(\"  Accuracy: {0:.2f}\".format(eval_accuracy/nb_eval_steps))\n","    print(\"  Validation took: {:}\".format(format_time(time.time() - t0)))\n","\n","print(\"\")\n","print(\"Training complete!\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ki7MqPup4jyD","executionInfo":{"status":"ok","timestamp":1673945137075,"user_tz":-540,"elapsed":26672,"user":{"displayName":"송지빈","userId":"11346694006770834807"}},"outputId":"1978086d-841c-450b-eda1-ec8c8ec4c876"},"execution_count":161,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","======== Epoch 1 / 4 ========\n","Training...\n","\n","  Average training loss: 0.70\n","  Training epcoh took: 0:00:09\n","\n","Running Validation...\n","  Accuracy: 0.47\n","  Validation took: 0:00:00\n","\n","======== Epoch 2 / 4 ========\n","Training...\n","\n","  Average training loss: 0.70\n","  Training epcoh took: 0:00:06\n","\n","Running Validation...\n","  Accuracy: 0.47\n","  Validation took: 0:00:00\n","\n","======== Epoch 3 / 4 ========\n","Training...\n","\n","  Average training loss: 0.70\n","  Training epcoh took: 0:00:06\n","\n","Running Validation...\n","  Accuracy: 0.47\n","  Validation took: 0:00:00\n","\n","======== Epoch 4 / 4 ========\n","Training...\n","\n","  Average training loss: 0.70\n","  Training epcoh took: 0:00:06\n","\n","Running Validation...\n","  Accuracy: 0.37\n","  Validation took: 0:00:00\n","\n","Training complete!\n"]}]},{"cell_type":"markdown","source":["# 테스트셋 평가"],"metadata":{"id":"Rdc3qWVw4xAV"}},{"cell_type":"code","source":["#시작 시간 설정\n","t0 = time.time()\n","\n","# 평가모드로 변경\n","model.eval()\n","\n","# 변수 초기화\n","eval_loss, eval_accuracy = 0, 0\n","nb_eval_steps, nb_eval_examples = 0, 0\n","\n","# 데이터로더에서 배치만큼 반복하여 가져옴\n","for step, batch in enumerate(test_dataloader):\n","    # 경과 정보 표시\n","    if step % 100 == 0 and not step == 0:\n","        elapsed = format_time(time.time() - t0)\n","        print('  Batch {:>5,}  of  {:>5,}.    Elapsed: {:}.'.format(step, len(test_dataloader), elapsed))\n","\n","    # 배치를 GPU에 넣음\n","    batch = tuple(t.to(device) for t in batch)\n","    \n","    # 배치에서 데이터 추출\n","    b_input_ids, b_input_mask, b_labels = batch\n","    \n","    # 그래디언트 계산 안함\n","    with torch.no_grad():     \n","        # Forward 수행\n","        outputs = model(b_input_ids, \n","                        token_type_ids=None, \n","                        attention_mask=b_input_mask)\n","    \n","    # 로스 구함\n","    logits = outputs[0]\n","\n","    # CPU로 데이터 이동\n","    logits = logits.detach().cpu().numpy()\n","    label_ids = b_labels.to('cpu').numpy()\n","    \n","    # 출력 로짓과 라벨을 비교하여 정확도 계산\n","    tmp_eval_accuracy = flat_accuracy(logits, label_ids)\n","    eval_accuracy += tmp_eval_accuracy\n","    nb_eval_steps += 1\n","\n","print(\"\")\n","print(\"Accuracy: {0:.2f}\".format(eval_accuracy/nb_eval_steps))\n","print(\"Test took: {:}\".format(format_time(time.time() - t0)))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"dTvOlkyZ6Ipg","executionInfo":{"status":"ok","timestamp":1673945199066,"user_tz":-540,"elapsed":1105,"user":{"displayName":"송지빈","userId":"11346694006770834807"}},"outputId":"0acc4f28-107a-4b9a-c4bf-ef534c0629fc"},"execution_count":162,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","Accuracy: 0.50\n","Test took: 0:00:01\n"]}]},{"cell_type":"markdown","source":["# 새로운 문장 테스트"],"metadata":{"id":"KHT_Eb916Kql"}},{"cell_type":"code","source":["# 입력 데이터 변환\n","def convert_input_data(sentences):\n","\n","    # BERT의 토크나이저로 문장을 토큰으로 분리\n","    tokenized_texts = [tokenizer.tokenize(sent) for sent in sentences]\n","\n","    # 입력 토큰의 최대 시퀀스 길이\n","    MAX_LEN = 128\n","\n","    # 토큰을 숫자 인덱스로 변환\n","    input_ids = [tokenizer.convert_tokens_to_ids(x) for x in tokenized_texts]\n","    \n","    # 문장을 MAX_LEN 길이에 맞게 자르고, 모자란 부분을 패딩 0으로 채움\n","    input_ids = pad_sequences(input_ids, maxlen=MAX_LEN, dtype=\"long\", truncating=\"post\", padding=\"post\")\n","\n","    # 어텐션 마스크 초기화\n","    attention_masks = []\n","\n","    # 어텐션 마스크를 패딩이 아니면 1, 패딩이면 0으로 설정\n","    # 패딩 부분은 BERT 모델에서 어텐션을 수행하지 않아 속도 향상\n","    for seq in input_ids:\n","        seq_mask = [float(i>0) for i in seq]\n","        attention_masks.append(seq_mask)\n","\n","    # 데이터를 파이토치의 텐서로 변환\n","    inputs = torch.tensor(input_ids)\n","    masks = torch.tensor(attention_masks)\n","\n","    return inputs, masks"],"metadata":{"id":"8fIu0TaG6OvG","executionInfo":{"status":"ok","timestamp":1673945225645,"user_tz":-540,"elapsed":464,"user":{"displayName":"송지빈","userId":"11346694006770834807"}}},"execution_count":163,"outputs":[]},{"cell_type":"code","source":["# 문장 테스트\n","def test_sentences(sentences):\n","\n","    # 평가모드로 변경\n","    model.eval()\n","\n","    # 문장을 입력 데이터로 변환\n","    inputs, masks = convert_input_data(sentences)\n","\n","    # 데이터를 GPU에 넣음\n","    b_input_ids = inputs.to(device)\n","    b_input_mask = masks.to(device)\n","            \n","    # 그래디언트 계산 안함\n","    with torch.no_grad():     \n","        # Forward 수행\n","        outputs = model(b_input_ids, \n","                        token_type_ids=None, \n","                        attention_mask=b_input_mask)\n","\n","    # 로스 구함\n","    logits = outputs[0]\n","\n","    # CPU로 데이터 이동\n","    logits = logits.detach().cpu().numpy()\n","\n","    return logits"],"metadata":{"id":"JOYI5O2H6RO2","executionInfo":{"status":"ok","timestamp":1673945232524,"user_tz":-540,"elapsed":412,"user":{"displayName":"송지빈","userId":"11346694006770834807"}}},"execution_count":164,"outputs":[]},{"cell_type":"code","source":["logits = test_sentences(['더 나은 학교생활 하고 싶어'])\n","print(logits)\n","\n","if np.argmax(logits) == 1 :\n","    print(\"연애 관련 대화\")\n","elif np.argmax(logits) == 0 :\n","    print(\"일상 대화\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"5J-dEf_h6TCY","executionInfo":{"status":"ok","timestamp":1673945243711,"user_tz":-540,"elapsed":618,"user":{"displayName":"송지빈","userId":"11346694006770834807"}},"outputId":"8acf7ab0-ce3a-4d13-d83b-c0473f139bf5"},"execution_count":165,"outputs":[{"output_type":"stream","name":"stdout","text":["[[0.17283234 0.16009946]]\n","일상 대화\n"]}]},{"cell_type":"code","source":["logits = test_sentences(['저녁 뭘 먹을지 추천해줘'])\n","\n","print(logits)\n","if np.argmax(logits) == 1 :\n","    print(\"연애 관련 대화\")\n","elif np.argmax(logits) == 0 :\n","    print(\"일상 대화\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"MUb1pE0D6Vtm","executionInfo":{"status":"ok","timestamp":1673945275276,"user_tz":-540,"elapsed":409,"user":{"displayName":"송지빈","userId":"11346694006770834807"}},"outputId":"9d8cea19-d205-4f60-995f-06ce71e9a6f4"},"execution_count":166,"outputs":[{"output_type":"stream","name":"stdout","text":["[[0.17177275 0.16132557]]\n","일상 대화\n"]}]},{"cell_type":"code","source":["logits = test_sentences(['여자친구한테 선물 뭘로 줄까?'])\n","\n","print(logits)\n","if np.argmax(logits) == 1 :\n","    print(\"연애 관련 대화\")\n","elif np.argmax(logits) == 0 :\n","    print(\"일상 대화\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ViOU4rSQ6dZD","executionInfo":{"status":"ok","timestamp":1673945288263,"user_tz":-540,"elapsed":20,"user":{"displayName":"송지빈","userId":"11346694006770834807"}},"outputId":"68482c54-e087-4ec4-d25a-805e7bdde870"},"execution_count":168,"outputs":[{"output_type":"stream","name":"stdout","text":["[[0.17058024 0.15684107]]\n","일상 대화\n"]}]},{"cell_type":"markdown","source":["# KoBert 모델 만들기"],"metadata":{"id":"8pxA74_j6ftf"}},{"cell_type":"markdown","source":["## 1. Colab 환경 설정"],"metadata":{"id":"lX9vKOtF7nVM"}},{"cell_type":"code","source":["!pip install git+https://git@github.com/SKTBrain/KoBERT.git@master"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"GfN_oc0W6_x_","executionInfo":{"status":"ok","timestamp":1673945647077,"user_tz":-540,"elapsed":148458,"user":{"displayName":"송지빈","userId":"11346694006770834807"}},"outputId":"1f8b9d13-1436-4edb-891d-2d4e1b2d9dec"},"execution_count":171,"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting git+https://****@github.com/SKTBrain/KoBERT.git@master\n","  Cloning https://****@github.com/SKTBrain/KoBERT.git (to revision master) to /tmp/pip-req-build-uavin68_\n","  Running command git clone --filter=blob:none --quiet 'https://****@github.com/SKTBrain/KoBERT.git' /tmp/pip-req-build-uavin68_\n","  Resolved https://****@github.com/SKTBrain/KoBERT.git to commit 47a69af87928fc24e20f571fe10c3cc9dd9af9a3\n","  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","Collecting boto3<=1.15.18\n","  Downloading boto3-1.15.18-py2.py3-none-any.whl (129 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m129.1/129.1 KB\u001b[0m \u001b[31m8.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting gluonnlp<=0.10.0,>=0.6.0\n","  Downloading gluonnlp-0.10.0.tar.gz (344 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m344.5/344.5 KB\u001b[0m \u001b[31m3.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","Collecting mxnet<=1.7.0.post2,>=1.4.0\n","  Downloading mxnet-1.7.0.post2-py2.py3-none-manylinux2014_x86_64.whl (54.7 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m54.7/54.7 MB\u001b[0m \u001b[31m18.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting onnxruntime<=1.8.0,==1.8.0\n","  Downloading onnxruntime-1.8.0-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.5 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.5/4.5 MB\u001b[0m \u001b[31m83.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting sentencepiece<=0.1.96,>=0.1.6\n","  Downloading sentencepiece-0.1.96-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.2 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m70.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting torch<=1.10.1,>=1.7.0\n","  Downloading torch-1.10.1-cp38-cp38-manylinux1_x86_64.whl (881.9 MB)\n","\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m \u001b[32m881.9/881.9 MB\u001b[0m \u001b[31m205.0 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0mtcmalloc: large alloc 1102397440 bytes == 0x3a908000 @  0x7fe15a58e615 0x5d6f4c 0x51edd1 0x51ef5b 0x4f750a 0x4997a2 0x55cd91 0x5d8941 0x4997a2 0x55cd91 0x5d8941 0x4997a2 0x55cd91 0x5d8941 0x4997a2 0x55cd91 0x5d8941 0x4997a2 0x55cd91 0x5d8941 0x4997a2 0x5d8868 0x4997a2 0x55cd91 0x5d8941 0x49abe4 0x55cd91 0x5d8941 0x4997a2 0x55cd91 0x5d8941\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m881.9/881.9 MB\u001b[0m \u001b[31m1.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting transformers<=4.8.1,>=4.8.1\n","  Downloading transformers-4.8.1-py3-none-any.whl (2.5 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.5/2.5 MB\u001b[0m \u001b[31m60.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: numpy>=1.16.6 in /usr/local/lib/python3.8/dist-packages (from onnxruntime<=1.8.0,==1.8.0->kobert==0.2.3) (1.21.6)\n","Requirement already satisfied: flatbuffers in /usr/local/lib/python3.8/dist-packages (from onnxruntime<=1.8.0,==1.8.0->kobert==0.2.3) (1.12)\n","Requirement already satisfied: protobuf in /usr/local/lib/python3.8/dist-packages (from onnxruntime<=1.8.0,==1.8.0->kobert==0.2.3) (3.19.6)\n","Collecting s3transfer<0.4.0,>=0.3.0\n","  Downloading s3transfer-0.3.7-py2.py3-none-any.whl (73 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m73.4/73.4 KB\u001b[0m \u001b[31m9.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting jmespath<1.0.0,>=0.7.1\n","  Downloading jmespath-0.10.0-py2.py3-none-any.whl (24 kB)\n","Collecting botocore<1.19.0,>=1.18.18\n","  Downloading botocore-1.18.18-py2.py3-none-any.whl (6.7 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.7/6.7 MB\u001b[0m \u001b[31m92.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: cython in /usr/local/lib/python3.8/dist-packages (from gluonnlp<=0.10.0,>=0.6.0->kobert==0.2.3) (0.29.32)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.8/dist-packages (from gluonnlp<=0.10.0,>=0.6.0->kobert==0.2.3) (21.3)\n","Requirement already satisfied: requests<3,>=2.20.0 in /usr/local/lib/python3.8/dist-packages (from mxnet<=1.7.0.post2,>=1.4.0->kobert==0.2.3) (2.25.1)\n","Collecting graphviz<0.9.0,>=0.8.1\n","  Downloading graphviz-0.8.4-py2.py3-none-any.whl (16 kB)\n","Requirement already satisfied: typing-extensions in /usr/local/lib/python3.8/dist-packages (from torch<=1.10.1,>=1.7.0->kobert==0.2.3) (4.4.0)\n","Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.8/dist-packages (from transformers<=4.8.1,>=4.8.1->kobert==0.2.3) (4.64.1)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.8/dist-packages (from transformers<=4.8.1,>=4.8.1->kobert==0.2.3) (3.9.0)\n","Collecting huggingface-hub==0.0.12\n","  Downloading huggingface_hub-0.0.12-py3-none-any.whl (37 kB)\n","Collecting sacremoses\n","  Downloading sacremoses-0.0.53.tar.gz (880 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m880.6/880.6 KB\u001b[0m \u001b[31m38.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","Collecting tokenizers<0.11,>=0.10.1\n","  Downloading tokenizers-0.10.3-cp38-cp38-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (3.3 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.3/3.3 MB\u001b[0m \u001b[31m68.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.8/dist-packages (from transformers<=4.8.1,>=4.8.1->kobert==0.2.3) (2022.6.2)\n","Requirement already satisfied: pyyaml in /usr/local/lib/python3.8/dist-packages (from transformers<=4.8.1,>=4.8.1->kobert==0.2.3) (6.0)\n","Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /usr/local/lib/python3.8/dist-packages (from botocore<1.19.0,>=1.18.18->boto3<=1.15.18->kobert==0.2.3) (2.8.2)\n","Requirement already satisfied: urllib3<1.26,>=1.20 in /usr/local/lib/python3.8/dist-packages (from botocore<1.19.0,>=1.18.18->boto3<=1.15.18->kobert==0.2.3) (1.24.3)\n","Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.8/dist-packages (from packaging->gluonnlp<=0.10.0,>=0.6.0->kobert==0.2.3) (3.0.9)\n","Requirement already satisfied: chardet<5,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests<3,>=2.20.0->mxnet<=1.7.0.post2,>=1.4.0->kobert==0.2.3) (4.0.0)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests<3,>=2.20.0->mxnet<=1.7.0.post2,>=1.4.0->kobert==0.2.3) (2.10)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests<3,>=2.20.0->mxnet<=1.7.0.post2,>=1.4.0->kobert==0.2.3) (2022.12.7)\n","Requirement already satisfied: six in /usr/local/lib/python3.8/dist-packages (from sacremoses->transformers<=4.8.1,>=4.8.1->kobert==0.2.3) (1.15.0)\n","Requirement already satisfied: click in /usr/local/lib/python3.8/dist-packages (from sacremoses->transformers<=4.8.1,>=4.8.1->kobert==0.2.3) (7.1.2)\n","Requirement already satisfied: joblib in /usr/local/lib/python3.8/dist-packages (from sacremoses->transformers<=4.8.1,>=4.8.1->kobert==0.2.3) (1.2.0)\n","Building wheels for collected packages: kobert, gluonnlp, sacremoses\n","  Building wheel for kobert (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for kobert: filename=kobert-0.2.3-py3-none-any.whl size=15708 sha256=117719b0c65e96a9163f52c463a268198c81c618344f165e6d742d22e8777b38\n","  Stored in directory: /tmp/pip-ephem-wheel-cache-uswvmlss/wheels/bf/5f/74/81bf3a1332130eb6629ecf58876a8746b77021e7d7b0638e91\n","  Building wheel for gluonnlp (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for gluonnlp: filename=gluonnlp-0.10.0-cp38-cp38-linux_x86_64.whl size=619643 sha256=75fda1e7d2f05fb9880e0b9761f4d9b2ae29762da49f856e2ce9297a7ede00a3\n","  Stored in directory: /root/.cache/pip/wheels/b6/93/9d/2237550c409eb3ed725d6302b7897ddd9a037b40cef66dcd9c\n","  Building wheel for sacremoses (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for sacremoses: filename=sacremoses-0.0.53-py3-none-any.whl size=895260 sha256=a650d743189c609db885f72e2bca2f43f6a14f519156fc4067a5d625a4ad8815\n","  Stored in directory: /root/.cache/pip/wheels/82/ab/9b/c15899bf659ba74f623ac776e861cf2eb8608c1825ddec66a4\n","Successfully built kobert gluonnlp sacremoses\n","Installing collected packages: tokenizers, sentencepiece, torch, sacremoses, onnxruntime, jmespath, graphviz, mxnet, huggingface-hub, gluonnlp, botocore, transformers, s3transfer, boto3, kobert\n","  Attempting uninstall: tokenizers\n","    Found existing installation: tokenizers 0.13.2\n","    Uninstalling tokenizers-0.13.2:\n","      Successfully uninstalled tokenizers-0.13.2\n","  Attempting uninstall: torch\n","    Found existing installation: torch 1.13.0+cu116\n","    Uninstalling torch-1.13.0+cu116:\n","      Successfully uninstalled torch-1.13.0+cu116\n","  Attempting uninstall: graphviz\n","    Found existing installation: graphviz 0.10.1\n","    Uninstalling graphviz-0.10.1:\n","      Successfully uninstalled graphviz-0.10.1\n","  Attempting uninstall: huggingface-hub\n","    Found existing installation: huggingface-hub 0.11.1\n","    Uninstalling huggingface-hub-0.11.1:\n","      Successfully uninstalled huggingface-hub-0.11.1\n","  Attempting uninstall: transformers\n","    Found existing installation: transformers 4.25.1\n","    Uninstalling transformers-4.25.1:\n","      Successfully uninstalled transformers-4.25.1\n","\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n","torchvision 0.14.0+cu116 requires torch==1.13.0, but you have torch 1.10.1 which is incompatible.\n","torchtext 0.14.0 requires torch==1.13.0, but you have torch 1.10.1 which is incompatible.\n","torchaudio 0.13.0+cu116 requires torch==1.13.0, but you have torch 1.10.1 which is incompatible.\u001b[0m\u001b[31m\n","\u001b[0mSuccessfully installed boto3-1.15.18 botocore-1.18.18 gluonnlp-0.10.0 graphviz-0.8.4 huggingface-hub-0.0.12 jmespath-0.10.0 kobert-0.2.3 mxnet-1.7.0.post2 onnxruntime-1.8.0 s3transfer-0.3.7 sacremoses-0.0.53 sentencepiece-0.1.96 tokenizers-0.10.3 torch-1.10.1 transformers-4.8.1\n"]}]},{"cell_type":"code","source":["import torch\n","from torch import nn\n","import torch.nn.functional as F\n","import torch.optim as optim\n","from torch.utils.data import Dataset, DataLoader\n","import gluonnlp as nlp\n","import numpy as np\n","from tqdm import tqdm, tqdm_notebook\n","\n","#kobert\n","from kobert.utils import get_tokenizer\n","from kobert.pytorch_kobert import get_pytorch_kobert_model\n","\n","#transformers\n","from transformers import AdamW\n","from transformers.optimization import get_cosine_schedule_with_warmup"],"metadata":{"id":"VN7ILC3D68tQ","executionInfo":{"status":"ok","timestamp":1673948284892,"user_tz":-540,"elapsed":473,"user":{"displayName":"송지빈","userId":"11346694006770834807"}}},"execution_count":202,"outputs":[]},{"cell_type":"code","source":["#BERT 모델, Vocabulary 불러오기\n","bertmodel, vocab = get_pytorch_kobert_model()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"lftR-vnT6999","executionInfo":{"status":"ok","timestamp":1673945735139,"user_tz":-540,"elapsed":4503,"user":{"displayName":"송지빈","userId":"11346694006770834807"}},"outputId":"ea3347c4-bb5c-4bb9-ff27-27e11f01988f"},"execution_count":177,"outputs":[{"output_type":"stream","name":"stdout","text":["using cached model. /content/.cache/kobert_v1.zip\n","using cached model. /content/.cache/kobert_news_wiki_ko_cased-1087f8699e.spiece\n"]}]},{"cell_type":"markdown","source":["## 2. 데이터셋 전처리"],"metadata":{"id":"W1dV06hE7lfP"}},{"cell_type":"markdown","source":["## 3.Train data & Test data"],"metadata":{"id":"vaGsP1sE8mo8"}},{"cell_type":"code","source":["print(len(train))\n","print(len(test))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"LilPwJDn8INX","executionInfo":{"status":"ok","timestamp":1673945811607,"user_tz":-540,"elapsed":377,"user":{"displayName":"송지빈","userId":"11346694006770834807"}},"outputId":"85c730b4-4c44-4e0f-a73f-61acbcbb83d8"},"execution_count":179,"outputs":[{"output_type":"stream","name":"stdout","text":["300\n","100\n"]}]},{"cell_type":"markdown","source":["## 4.KoBERT 입력 데이터로 만들기"],"metadata":{"id":"6MFdPh308gP5"}},{"cell_type":"code","source":["train[:5]"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":206},"id":"8yBxvbydDWs8","executionInfo":{"status":"ok","timestamp":1673947611446,"user_tz":-540,"elapsed":12,"user":{"displayName":"송지빈","userId":"11346694006770834807"}},"outputId":"a67932d6-91f9-4cb7-dc87-592e11b75ef3"},"execution_count":190,"outputs":[{"output_type":"execute_result","data":{"text/plain":["                                      title  \\\n","247      허은아 “친윤이고 검사 출신이면 당협 쇼핑하는 현실 부끄럽다”   \n","110                 與 당권주자들, 새해벽두부터 줄줄이 출정식   \n","16     與조강특위, 조직위원장 42명 선임…‘이재명 저격수’ 장영하 포함   \n","66      尹 “전쟁 준비” 발언에…이재명 “안보무능 정권의 철부지 행동”   \n","153  野 “1월 임시국회 소집 불가피”…與 “이재명 방탄국회 열겠다는 것”   \n","\n","                                           new_article news  \n","247  은 국민 힘 의원 29일 이준석 대표 시절 내정 됐던 서울 동대문 당원 협의 회 당...    0  \n","110  권성동 1월 6일 출마 선언 계획 안철수 늦어도 설연휴 전 밝힐듯 2023년 새해 ...    1  \n","16   국민 힘 조직 강화 특별 위원회 조강 특위 는 29일 총 42 명의 국회의원 선거구...    1  \n","66   민주당 윤석열 대통령 전쟁 준비 발언 두고 안보 불안 부추기고 며 공세 나섰다 이재...    1  \n","153  이재명 민주당 대표 박찬 대 최고 위원 지난 23일 오후 서울 여의도 국회 열린 본...    1  "],"text/html":["\n","  <div id=\"df-b28bb9ed-155c-4843-bcdb-772e35e56443\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>title</th>\n","      <th>new_article</th>\n","      <th>news</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>247</th>\n","      <td>허은아 “친윤이고 검사 출신이면 당협 쇼핑하는 현실 부끄럽다”</td>\n","      <td>은 국민 힘 의원 29일 이준석 대표 시절 내정 됐던 서울 동대문 당원 협의 회 당...</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>110</th>\n","      <td>與 당권주자들, 새해벽두부터 줄줄이 출정식</td>\n","      <td>권성동 1월 6일 출마 선언 계획 안철수 늦어도 설연휴 전 밝힐듯 2023년 새해 ...</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>16</th>\n","      <td>與조강특위, 조직위원장 42명 선임…‘이재명 저격수’ 장영하 포함</td>\n","      <td>국민 힘 조직 강화 특별 위원회 조강 특위 는 29일 총 42 명의 국회의원 선거구...</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>66</th>\n","      <td>尹 “전쟁 준비” 발언에…이재명 “안보무능 정권의 철부지 행동”</td>\n","      <td>민주당 윤석열 대통령 전쟁 준비 발언 두고 안보 불안 부추기고 며 공세 나섰다 이재...</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>153</th>\n","      <td>野 “1월 임시국회 소집 불가피”…與 “이재명 방탄국회 열겠다는 것”</td>\n","      <td>이재명 민주당 대표 박찬 대 최고 위원 지난 23일 오후 서울 여의도 국회 열린 본...</td>\n","      <td>1</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-b28bb9ed-155c-4843-bcdb-772e35e56443')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-b28bb9ed-155c-4843-bcdb-772e35e56443 button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-b28bb9ed-155c-4843-bcdb-772e35e56443');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "]},"metadata":{},"execution_count":190}]},{"cell_type":"code","source":["# 토큰화 & 패딩\n","class BERTDataset(Dataset):\n","    def __init__(self, dataset, sent_idx, label_idx, bert_tokenizer, max_len,\n","                 pad, pair):\n","        transform = nlp.data.BERTSentenceTransform(\n","            bert_tokenizer, max_seq_length=max_len, pad=pad, pair=pair)\n","        self.sentences = [transform([i[sent_idx]]) for i in dataset]\n","\n","        labels = test['news'].values\n","        self.labels = labels.astype(np.int)\n","\n","        # self.labels = [np.int32(i[label_idx]) for i in dataset]\n","        \n","\n","    def __getitem__(self, i):\n","        return (self.sentences[i] + (self.labels[i], ))\n","\n","    def __len__(self):\n","        return (len(self.labels))"],"metadata":{"id":"27Pk76En8pM0","executionInfo":{"status":"ok","timestamp":1673948054884,"user_tz":-540,"elapsed":770,"user":{"displayName":"송지빈","userId":"11346694006770834807"}}},"execution_count":192,"outputs":[]},{"cell_type":"code","source":["# 하이퍼파라미터 조정 Batch size는 64, epochs는 5, learning rate는 5e-5\n","# Setting parameters\n","max_len = 64\n","batch_size = 64\n","warmup_ratio = 0.1\n","num_epochs = 5\n","max_grad_norm = 1\n","log_interval = 200\n","learning_rate =  5e-5"],"metadata":{"id":"wf0eSrKs8zAD","executionInfo":{"status":"ok","timestamp":1673948057929,"user_tz":-540,"elapsed":28,"user":{"displayName":"송지빈","userId":"11346694006770834807"}}},"execution_count":193,"outputs":[]},{"cell_type":"code","source":["#토큰화\n","tokenizer = get_tokenizer()\n","tok = nlp.data.BERTSPTokenizer(tokenizer, vocab, lower=False)\n","\n","data_train = BERTDataset(train, 1, 2, tok, max_len, True, False)\n","data_test = BERTDataset(test, 1, 2, tok, max_len, True, False)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"GRm23V2u86OF","executionInfo":{"status":"ok","timestamp":1673948057932,"user_tz":-540,"elapsed":24,"user":{"displayName":"송지빈","userId":"11346694006770834807"}},"outputId":"250e45cd-8e2c-4f28-a7fa-314a6d8e9b39"},"execution_count":194,"outputs":[{"output_type":"stream","name":"stdout","text":["using cached model. /content/.cache/kobert_news_wiki_ko_cased-1087f8699e.spiece\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-192-e65f04dac005>:10: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\n","Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n","  self.labels = labels.astype(np.int)\n"]}]},{"cell_type":"code","source":["# 첫 번째는 패딩된 시퀀스, 두 번째는 길이와 타입에 대한 내용, 세 번째는 어텐션 마스크 시퀀스\n","data_train[0]"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"LbxLg6Zw8-TL","executionInfo":{"status":"ok","timestamp":1673948125170,"user_tz":-540,"elapsed":25,"user":{"displayName":"송지빈","userId":"11346694006770834807"}},"outputId":"07f4abed-60b9-4a0d-c2d4-b70e971ce6f1"},"execution_count":196,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(array([  2, 517, 405,   3,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n","          1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n","          1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n","          1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n","          1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1],\n","       dtype=int32),\n"," array(4, dtype=int32),\n"," array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n","       dtype=int32),\n"," 0)"]},"metadata":{},"execution_count":196}]},{"cell_type":"code","source":["# torch 형식의 dataset을 만들어준다.\n","train_dataloader = torch.utils.data.DataLoader(data_train, batch_size=batch_size, num_workers=5)\n","test_dataloader = torch.utils.data.DataLoader(data_test, batch_size=batch_size, num_workers=5)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ztWRDpoPFVII","executionInfo":{"status":"ok","timestamp":1673948152960,"user_tz":-540,"elapsed":25,"user":{"displayName":"송지빈","userId":"11346694006770834807"}},"outputId":"bfd4994f-09cc-4aca-88a3-03f6dca185c1"},"execution_count":197,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.8/dist-packages/torch/utils/data/dataloader.py:554: UserWarning: This DataLoader will create 5 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n","  assert self._num_workers == 0\n"]}]},{"cell_type":"markdown","source":["## 5. KoBERT 학습 모델 만들기"],"metadata":{"id":"GfB1VFjcFb7L"}},{"cell_type":"code","source":["class BERTClassifier(nn.Module):\n","    def __init__(self,\n","                 bert,\n","                 hidden_size = 768,\n","                 num_classes=2,   ##클래스 수 조정##\n","                 dr_rate=None,\n","                 params=None):\n","        super(BERTClassifier, self).__init__()\n","        self.bert = bert\n","        self.dr_rate = dr_rate\n","                 \n","        self.classifier = nn.Linear(hidden_size , num_classes)\n","        if dr_rate:\n","            self.dropout = nn.Dropout(p=dr_rate)\n","    \n","    def gen_attention_mask(self, token_ids, valid_length):\n","        attention_mask = torch.zeros_like(token_ids)\n","        for i, v in enumerate(valid_length):\n","            attention_mask[i][:v] = 1\n","        return attention_mask.float()\n","\n","    def forward(self, token_ids, valid_length, segment_ids):\n","        attention_mask = self.gen_attention_mask(token_ids, valid_length)\n","        \n","        _, pooler = self.bert(input_ids = token_ids, token_type_ids = segment_ids.long(), attention_mask = attention_mask.float().to(token_ids.device))\n","        if self.dr_rate:\n","            out = self.dropout(pooler)\n","        return self.classifier(out)"],"metadata":{"id":"06MusJpfFfrO","executionInfo":{"status":"ok","timestamp":1673948236346,"user_tz":-540,"elapsed":582,"user":{"displayName":"송지빈","userId":"11346694006770834807"}}},"execution_count":200,"outputs":[]},{"cell_type":"code","source":["#BERT 모델 불러오기\n","model = BERTClassifier(bertmodel,  dr_rate=0.5).to(device)\n","\n","#optimizer와 schedule 설정\n","no_decay = ['bias', 'LayerNorm.weight']\n","optimizer_grouped_parameters = [\n","    {'params': [p for n, p in model.named_parameters() if not any(nd in n for nd in no_decay)], 'weight_decay': 0.01},\n","    {'params': [p for n, p in model.named_parameters() if any(nd in n for nd in no_decay)], 'weight_decay': 0.0}\n","]\n","\n","optimizer = AdamW(optimizer_grouped_parameters, lr=learning_rate)\n","loss_fn = nn.CrossEntropyLoss()\n","\n","t_total = len(train_dataloader) * num_epochs\n","warmup_step = int(t_total * warmup_ratio)\n","\n","scheduler = get_cosine_schedule_with_warmup(optimizer, num_warmup_steps=warmup_step, num_training_steps=t_total)\n","\n","#정확도 측정을 위한 함수 정의\n","def calc_accuracy(X,Y):\n","    max_vals, max_indices = torch.max(X, 1)\n","    train_acc = (max_indices == Y).sum().data.cpu().numpy()/max_indices.size()[0]\n","    return train_acc\n","    \n","train_dataloader"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Xp4z_OwKFsSH","executionInfo":{"status":"ok","timestamp":1673948295196,"user_tz":-540,"elapsed":22,"user":{"displayName":"송지빈","userId":"11346694006770834807"}},"outputId":"e15737a9-6640-4fc1-d6cc-d289ed1ca94f"},"execution_count":203,"outputs":[{"output_type":"execute_result","data":{"text/plain":["<torch.utils.data.dataloader.DataLoader at 0x7f84ebe49340>"]},"metadata":{},"execution_count":203}]},{"cell_type":"markdown","source":["## 6. KoBERT 모델 학습시키기"],"metadata":{"id":"OC_2DH3kFus4"}},{"cell_type":"code","source":["for e in range(num_epochs):\n","    train_acc = 0.0\n","    test_acc = 0.0\n","    model.train()\n","    for batch_id, (token_ids, valid_length, segment_ids, label) in enumerate(tqdm_notebook(train_dataloader)):\n","        optimizer.zero_grad()\n","        token_ids = token_ids.long().to(device)\n","        segment_ids = segment_ids.long().to(device)\n","        valid_length= valid_length\n","        label = label.long().to(device)\n","        out = model(token_ids, valid_length, segment_ids)\n","        loss = loss_fn(out, label)\n","        loss.backward()\n","        torch.nn.utils.clip_grad_norm_(model.parameters(), max_grad_norm)\n","        optimizer.step()\n","        scheduler.step()  # Update learning rate schedule\n","        train_acc += calc_accuracy(out, label)\n","        if batch_id % log_interval == 0:\n","            print(\"epoch {} batch id {} loss {} train acc {}\".format(e+1, batch_id+1, loss.data.cpu().numpy(), train_acc / (batch_id+1)))\n","    print(\"epoch {} train acc {}\".format(e+1, train_acc / (batch_id+1)))\n","    \n","    model.eval()\n","    for batch_id, (token_ids, valid_length, segment_ids, label) in enumerate(tqdm_notebook(test_dataloader)):\n","        token_ids = token_ids.long().to(device)\n","        segment_ids = segment_ids.long().to(device)\n","        valid_length= valid_length\n","        label = label.long().to(device)\n","        out = model(token_ids, valid_length, segment_ids)\n","        test_acc += calc_accuracy(out, label)\n","    print(\"epoch {} test acc {}\".format(e+1, test_acc / (batch_id+1)))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":542,"referenced_widgets":["59d548d312cc434a91b4edc804f92818","8144706f38d543aca4caa246ea2cb3dd","649a5c1b98764380a75af0fd8c465d5f","bfd35328b164419f9a7e106e11ee0923","5be6aa90465240dfb6707e3d28c514db","a61914cc54124ebaa4c532271f421944","f7a842211be9411ebfc8ab6681362b1f","4eb6ca548bdb4dcb89540c8c1b8342aa","983816f06fe7419ca083822805baad69","b32dbdf975104f7aa60518a286a3dfbc","fd3149320c39457ea43c049373b561f0"]},"id":"MFhQR4NPGCsk","executionInfo":{"status":"error","timestamp":1673948319822,"user_tz":-540,"elapsed":623,"user":{"displayName":"송지빈","userId":"11346694006770834807"}},"outputId":"3ecb01be-8210-43ef-dd32-fc1c32650cc5"},"execution_count":204,"outputs":[{"output_type":"stream","name":"stderr","text":["<ipython-input-204-480b6a139979>:5: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0\n","Please use `tqdm.notebook.tqdm` instead of `tqdm.tqdm_notebook`\n","  for batch_id, (token_ids, valid_length, segment_ids, label) in enumerate(tqdm_notebook(train_dataloader)):\n"]},{"output_type":"display_data","data":{"text/plain":["  0%|          | 0/2 [00:00<?, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"59d548d312cc434a91b4edc804f92818"}},"metadata":{}},{"output_type":"error","ename":"IndexError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)","\u001b[0;32m<ipython-input-204-480b6a139979>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mtest_acc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mbatch_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtoken_ids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalid_length\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msegment_ids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtqdm_notebook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_dataloader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m         \u001b[0mtoken_ids\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtoken_ids\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlong\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.8/dist-packages/tqdm/notebook.py\u001b[0m in \u001b[0;36m__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    257\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    258\u001b[0m             \u001b[0mit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtqdm_notebook\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__iter__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 259\u001b[0;31m             \u001b[0;32mfor\u001b[0m \u001b[0mobj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mit\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    260\u001b[0m                 \u001b[0;31m# return super(tqdm...) will not catch exception\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    261\u001b[0m                 \u001b[0;32myield\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.8/dist-packages/tqdm/std.py\u001b[0m in \u001b[0;36m__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1193\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1194\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1195\u001b[0;31m             \u001b[0;32mfor\u001b[0m \u001b[0mobj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0miterable\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1196\u001b[0m                 \u001b[0;32myield\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1197\u001b[0m                 \u001b[0;31m# Update and possibly print the progressbar.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    626\u001b[0m     \u001b[0;31m#      `_utils.python_exit_status`. Since `atexit` hooks are executed in the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    627\u001b[0m     \u001b[0;31m#      reverse order of registration, we are guaranteed that this flag is\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 628\u001b[0;31m     \u001b[0;31m#      set before library resources we use are freed (which, at least in\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    629\u001b[0m     \u001b[0;31m#      CPython, is done via an `atexit` handler defined in\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    630\u001b[0m     \u001b[0;31m#      `multiprocessing/util.py`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_process_data\u001b[0;34m(self, data)\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/_utils.py\u001b[0m in \u001b[0;36mreraise\u001b[0;34m(self)\u001b[0m\n","\u001b[0;31mIndexError\u001b[0m: Caught IndexError in DataLoader worker process 0.\nOriginal Traceback (most recent call last):\n  File \"/usr/local/lib/python3.8/dist-packages/torch/utils/data/_utils/worker.py\", line 302, in _worker_loop\n    del data, idx, index, r  # save memory\n  File \"/usr/local/lib/python3.8/dist-packages/torch/utils/data/_utils/fetch.py\", line 58, in fetch\n  File \"/usr/local/lib/python3.8/dist-packages/torch/utils/data/_utils/fetch.py\", line 58, in <listcomp>\n  File \"<ipython-input-192-e65f04dac005>\", line 16, in __getitem__\n    return (self.sentences[i] + (self.labels[i], ))\nIndexError: list index out of range\n"]}]},{"cell_type":"code","source":[],"metadata":{"id":"8eq9k6Q4GEoI"},"execution_count":null,"outputs":[]}]}